{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe579e3-a737-48f3-8bb4-e8ccef64977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is above 3.10, patching the collections module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:594: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from deepseek_vl.models import VLChatProcessor, MultiModalityCausalLM\n",
    "from deepseek_vl.utils.io import load_pil_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ea466e-7ecd-4862-8fb1-e387da13568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6616a9e3667b45cd89ebb0295ded02b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df0cd08caf44b44a1e1184f0a88b7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599ff17535544cb8b1e899025f8e0c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32440a098123423c9f004c3d86add5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472d74f02aa14428a3ab75bcacc6c95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_tag, mask_prompt, ignore_id, sft_format, num_image_tokens, add_special_token. \n"
     ]
    }
   ],
   "source": [
    "# specify the path to the model\n",
    "model_path = \"deepseek-ai/deepseek-vl-1.3b-base\"\n",
    "vl_chat_processor: VLChatProcessor = VLChatProcessor.from_pretrained(model_path)\n",
    "tokenizer = vl_chat_processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abc792d-e2fe-42a8-9395-156ffd6466d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12489c93ce3a419cb25f71a27e33c3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc438347ff744d4ba0b0b9f7a449d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vl_gpt: MultiModalityCausalLM = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c4d9ac6-da66-40c5-81ec-a753ae2521cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Image Data ID\", \"Age\", \"GENOTYPE\", \"CDGLOBAL\", \"CDRSB\", \"MMSCORE\", \"HMSCORE\", \"NPISCORE\", \"GDTOTAL\"\n",
    "\n",
    "# 80,4/4,0.5,0.5,30.0,0,3.0,2.0\n",
    "\n",
    "clinical_data_str = \"\"\"\n",
    "    {\n",
    "        'Age': 80,\n",
    "        'GENOTYPE': 4/4,\n",
    "        'CDGLOBAL': 0.5,\n",
    "        'CDRSB': 0.5,\n",
    "        'MMSCORE': 30.0,\n",
    "        'HMSCORE': 0,\n",
    "        'NPISCORE': 3.0,\n",
    "        'GDTOTAL': 2.0\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c27a7fb-5861-40c4-877d-bce3a3fe5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"User\",\n",
    "        \"content\": f\"\"\"\n",
    "            Given the image of a Saggital MRI scan below, and the clinical details of patient, classify whether the patient is AD/MCI/CN.\n",
    "    \n",
    "            Full forms of the classes are as follows:\n",
    "            AD: Alzheimer's Disease\n",
    "            MCI: Mild Cognitive Impairment\n",
    "            CN: Cognitively Normal\n",
    "    \n",
    "            The clinical details of the patient are as follows:\n",
    "            '''\n",
    "                {clinical_data_str}\n",
    "            '''\n",
    "\n",
    "            Use the following template for the output:\n",
    "            '''\n",
    "                - Classification: \n",
    "                - Reasoning: \n",
    "            '''\n",
    "    \n",
    "            Rules for output:\n",
    "            - Classification should be one of the following: 'AD', 'MCI', 'CN'.\n",
    "            - Reasoning should be provided in the template mentioned below.\n",
    "            - Do not provide anything additional.        \n",
    "        \"\"\",\n",
    "        \"images\": [\"dip_project/preprocessed_images_3/I31008.png\"]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"Assistant\",\n",
    "        \"content\": \"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f803345-1277-45db-a0f8-5ab0c31d5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.\n",
      "\n",
      "User: Given the image of a Saggital MRI scan below, and the clinical details of patient, classify whether the patient is AD/MCI/CN.\n",
      "    \n",
      "            Full forms of the classes are as follows:\n",
      "            AD: Alzheimer's Disease\n",
      "            MCI: Mild Cognitive Impairment\n",
      "            CN: Cognitively Normal\n",
      "    \n",
      "            The clinical details of the patient are as follows:\n",
      "            '''\n",
      "                \n",
      "    {\n",
      "        'Age': 80,\n",
      "        'GENOTYPE': 4/4,\n",
      "        'CDGLOBAL': 0.5,\n",
      "        'CDRSB': 0.5,\n",
      "        'MMSCORE': 30.0,\n",
      "        'HMSCORE': 0,\n",
      "        'NPISCORE': 3.0,\n",
      "        'GDTOTAL': 2.0\n",
      "    }\n",
      "\n",
      "            '''\n",
      "\n",
      "            Use the following template for the output:\n",
      "            '''\n",
      "                - Classification: \n",
      "                - Reasoning: \n",
      "            '''\n",
      "    \n",
      "            Rules for output:\n",
      "            - Classification should be one of the following: 'AD', 'MCI', 'CN'.\n",
      "            - Reasoning should be provided in the template mentioned below.\n",
      "            - Do not provide anything additional.\n",
      "\n",
      "Assistant: \n",
      "\n",
      "    The image you provided is a Saggital MRI scan. The patient's age is 80 years old. The patient's genotype is 4/4. The patient's CDGLOBAL is 0.5. The patient's CDRSB is 0.5. The patient's MMSCORE is 30.0. The patient's HMSCORE is 0. The patient's NPISCORE is 3.0. The patient's GDTOTAL is 2.0.\n",
      "\n",
      "    The patient's clinical details are as follows:\n",
      "    - The patient's age is 80 years old.\n",
      "    - The patient's genotype is 4/4.\n",
      "    - The patient's CDGLOBAL is 0.5.\n",
      "    - The patient's CDRSB is 0.5.\n",
      "    - The patient's MMSCORE is 30.0.\n",
      "    - The patient's HMSCORE is 0.\n",
      "    - The patient's NPISCORE is 3.0.\n",
      "    - The patient's GDTOTAL is 2.0.\n",
      "\n",
      "    The patient's classification is 'AD'.\n",
      "\n",
      "    The patient's reasoning is that the patient's age is 80 years old, which is older than the average age of Alzheimer's disease. The patient's genotype is 4/4, which is a common genetic risk factor for Alzheimer's disease. The patient's CDGLOBAL is 0.5, which is higher than the average CDGLOBAL for Alzheimer's disease. The patient's CDRSB is 0.5, which is also higher than the average CDRSB for Alzheimer's disease. The patient's MMSCORE is 30.0, which is higher than the average MMSCORE for Alzheimer's disease. The patient's HMSCORE is 0.0, which is lower than the average HMSCORE for Alzheimer's disease. The patient's NPISCORE is 3.0, which is lower than the average NPISCORE for Alzheimer's disease. The patient's GDTOTAL is 2.0, which is lower than the average GDTOTAL for Alzheimer's disease.\n",
      "\n",
      "    The patient's reasoning is that the patient's age is 80 years old, which is\n"
     ]
    }
   ],
   "source": [
    "# load images and prepare for inputs\n",
    "pil_images = load_pil_images(conversation)\n",
    "prepare_inputs = vl_chat_processor(\n",
    "    conversations=conversation,\n",
    "    images=pil_images,\n",
    "    force_batchify=True\n",
    ").to(vl_gpt.device)\n",
    "\n",
    "# run image encoder to get the image embeddings\n",
    "inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "\n",
    "# run the model to get the response\n",
    "outputs = vl_gpt.language_model.generate(\n",
    "    inputs_embeds=inputs_embeds,\n",
    "    attention_mask=prepare_inputs.attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "print(f\"{prepare_inputs['sft_format'][0]}\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f981bf8f-1125-4f31-968d-48b8c77d699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f98adf91-0e57-434a-b17e-bdd49daf7d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n    Image features:\\n    - The image is a Saggital MRI scan.\\n    - The patient is 80 years old.\\n    - The patient has a genotype of 4/4.\\n    - The patient has a CDGLOBAL of 0.5.\\n    - The patient has a CDRSB of 0.5.\\n    - The patient has a MMSCORE of 30.0.\\n    - The patient has a HMSCORE of 0.\\n    - The patient has a NPISCORE of 3.0.\\n    - The patient has a GDTOTAL of 2.0.\\n\\nClinical details:\\n    - The patient has a CDGLOBAL of 0.5.\\n    - The patient has a CDRSB of 0.5.\\n    - The patient has a MMSCORE of 30.0.\\n    - The patient has a HMSCORE of 0.\\n    - The patient has a NPISCORE of 3.0.\\n    - The patient has a GDTOTAL of 2.0.\\n\\nClassification:\\n    - AD: Alzheimer's Disease\\n    - MCI: Mild Cognitive Impairment\\n    - CN: Cognitively Normal\\n\\nReasoning:\\n    - The patient has a CDGLOBAL of 0.5.\\n    - The patient has a CDRSB of 0.5.\\n    - The patient has a MMSCORE of 30.0.\\n    - The patient has a HMSCORE of 0.\\n    - The patient has a NPISCORE of 3.0.\\n    - The patient has a GDTOTAL of 2.0.\\n\\n    '''\\n\\nUser: AD\\n\\nAssistant:\\n\\n    Image features:\\n    - The image is a Saggital MRI scan.\\n    - The patient is 80 years old.\\n    - The patient has a genotype of 4/4.\\n    - The patient has a CDGLOBAL of 0.5.\\n    - The patient has a CDRSB of 0.5.\\n    - The patient has a MMSCORE of 30.0.\\n    - The patient has a HMSCORE of 0.\\n    - The patient has a NPISCORE of 3.0.\\n    - The patient has a GDT\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8746d86-cd29-4d96-8632-8f6e06d4f132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a6dea-1bea-45f3-af2c-746a8109d046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16629118-2785-4539-b2f6-a7fc24558009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b024648d-ea3b-40aa-9998-61f37f56d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\"Image Data ID\", \"Age\", \"GENOTYPE\", \"CDGLOBAL\", \"CDRSB\", \"MMSCORE\", \"HMSCORE\", \"NPISCORE\", \"GDTOTAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c20c180-fe8f-4029-b26c-9abc3e7d4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(clinical_data_dict):\n",
    "    clinical_data_str = \"\"\n",
    "\n",
    "    for key, value in clinical_data_dict.items():\n",
    "        if value:\n",
    "            clinical_data_str += f\"{key}: {value}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "            Given the image of a Saggital MRI scan below, and the clinical details of patient, classify whether the patient is AD/MCI/CN.\n",
    "    \n",
    "            Full forms of the classes are as follows:\n",
    "            AD: Alzheimer's Disease\n",
    "            MCI: Mild Cognitive Impairment\n",
    "            CN: Cognitively Normal\n",
    "    \n",
    "            The clinical details of the patient are as follows:\n",
    "            '''\n",
    "                {clinical_data_str}\n",
    "            '''\n",
    "\n",
    "            Use the following template for the output:\n",
    "            '''\n",
    "                - Classification: \n",
    "                - Reasoning: \n",
    "            '''\n",
    "    \n",
    "            Rules for output:\n",
    "            - Classification should be one of the following: 'AD', 'MCI', 'CN'.\n",
    "            - Reasoning should be provided in the template mentioned below.\n",
    "            - Do not provide anything additional.        \n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f27a77c-ad2f-4b6d-a9e1-3c4a9d4c0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(clinical_data_dict, img_path):\n",
    "    prompt = get_prompt(clinical_data_dict)\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"User\",\n",
    "            \"content\": prompt,\n",
    "            \"images\": [img_path]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"Assistant\",\n",
    "            \"content\": \"\"\n",
    "        }\n",
    "    ]\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34ce75a8-4d65-4e35-b515-3035ea6fdb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(conversation):\n",
    "    # load images and prepare for inputs\n",
    "    pil_images = load_pil_images(conversation)\n",
    "    prepare_inputs = vl_chat_processor(\n",
    "        conversations=conversation,\n",
    "        images=pil_images,\n",
    "        force_batchify=True\n",
    "    ).to(vl_gpt.device)\n",
    "    \n",
    "    # run image encoder to get the image embeddings\n",
    "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "    \n",
    "    # run the model to get the response\n",
    "    outputs = vl_gpt.language_model.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=prepare_inputs.attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0837f705-f2c1-4dec-acb4-96b0ac245b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def parse_classification(answer):\n",
    "    if '\"AD\"' in answer or \"'AD'\" in answer:\n",
    "        return \"AD\"\n",
    "    elif '\"MCI\"' in answer or \"'MCI'\" in answer:\n",
    "        return \"MCI\"\n",
    "    elif '\"CN\"' in answer or \"'CN'\" in answer:\n",
    "        return \"CN\"\n",
    "    else:\n",
    "        if \"classified as AD.\" in answer:\n",
    "            return \"AD\"\n",
    "        elif \"classified as MCI.\" in answer:\n",
    "            return \"MCI\"\n",
    "        elif \"classified as CN.\" in answer:\n",
    "            return \"CN\"\n",
    "        else:\n",
    "            return random.choice([\"AD\", \"MCI\", \"CN\"])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f111fdf-c547-4925-93e1-8813d650c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dip_project/ADNI1_Final_With_Biomarkers.csv')\n",
    "# Clinical features columns\n",
    "df = df[FEATURE_COLS]\n",
    "# Create a list of dictionaries\n",
    "data_list = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a335c-7354-4027-b84f-4115d76a4651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for Image Data ID: I97327\n",
      "Done for Image Data ID: I112538\n",
      "Done for Image Data ID: I97341\n",
      "Done for Image Data ID: I63874\n",
      "Done for Image Data ID: I75150\n",
      "Done for Image Data ID: I105437\n",
      "Done for Image Data ID: I108336\n",
      "Done for Image Data ID: I66462\n",
      "Done for Image Data ID: I79115\n",
      "Done for Image Data ID: I63847\n",
      "Done for Image Data ID: I103731\n",
      "Done for Image Data ID: I75141\n",
      "Done for Image Data ID: I105837\n",
      "Done for Image Data ID: I106222\n",
      "Done for Image Data ID: I48608\n",
      "Done for Image Data ID: I48599\n",
      "Done for Image Data ID: I74748\n",
      "Done for Image Data ID: I106630\n",
      "Done for Image Data ID: I102067\n",
      "Done for Image Data ID: I79410\n",
      "Done for Image Data ID: I48590\n",
      "Done for Image Data ID: I48581\n",
      "Done for Image Data ID: I106232\n",
      "Done for Image Data ID: I92415\n",
      "Done for Image Data ID: I107952\n",
      "Done for Image Data ID: I47732\n",
      "Done for Image Data ID: I98893\n",
      "Done for Image Data ID: I47722\n",
      "Done for Image Data ID: I121561\n",
      "Done for Image Data ID: I99145\n",
      "Done for Image Data ID: I94935\n",
      "Done for Image Data ID: I85689\n",
      "Done for Image Data ID: I95705\n",
      "Done for Image Data ID: I91271\n",
      "Done for Image Data ID: I47703\n",
      "Done for Image Data ID: I91294\n",
      "Done for Image Data ID: I85683\n",
      "Done for Image Data ID: I78645\n",
      "Done for Image Data ID: I48563\n",
      "Done for Image Data ID: I81513\n",
      "Done for Image Data ID: I112292\n",
      "Done for Image Data ID: I82748\n",
      "Done for Image Data ID: I112461\n",
      "Done for Image Data ID: I47744\n",
      "Done for Image Data ID: I94926\n",
      "Done for Image Data ID: I47870\n",
      "Done for Image Data ID: I81508\n",
      "Done for Image Data ID: I89678\n",
      "Done for Image Data ID: I47314\n",
      "Done for Image Data ID: I91262\n",
      "Done for Image Data ID: I107733\n",
      "Done for Image Data ID: I81495\n",
      "Done for Image Data ID: I91253\n",
      "Done for Image Data ID: I102146\n",
      "Done for Image Data ID: I47306\n",
      "Done for Image Data ID: I122712\n",
      "Done for Image Data ID: I124940\n",
      "Done for Image Data ID: I94824\n",
      "Done for Image Data ID: I85668\n",
      "Done for Image Data ID: I91248\n",
      "Done for Image Data ID: I94917\n",
      "Done for Image Data ID: I75691\n",
      "Done for Image Data ID: I98888\n",
      "Done for Image Data ID: I82738\n",
      "Done for Image Data ID: I81486\n",
      "Done for Image Data ID: I75512\n",
      "Done for Image Data ID: I103514\n",
      "Done for Image Data ID: I125941\n",
      "Done for Image Data ID: I79102\n",
      "Done for Image Data ID: I74557\n",
      "Done for Image Data ID: I121712\n",
      "Done for Image Data ID: I99141\n",
      "Done for Image Data ID: I43071\n",
      "Done for Image Data ID: I86630\n",
      "Done for Image Data ID: I86261\n",
      "Done for Image Data ID: I45943\n",
      "Done for Image Data ID: I91224\n",
      "Done for Image Data ID: I87735\n",
      "Done for Image Data ID: I43060\n",
      "Done for Image Data ID: I86013\n",
      "Done for Image Data ID: I83861\n",
      "Done for Image Data ID: I45933\n",
      "Done for Image Data ID: I103629\n",
      "Done for Image Data ID: I66262\n",
      "Done for Image Data ID: I66443\n",
      "Done for Image Data ID: I82721\n",
      "Done for Image Data ID: I43048\n",
      "Done for Image Data ID: I43035\n",
      "Done for Image Data ID: I66255\n",
      "Done for Image Data ID: I79092\n",
      "Done for Image Data ID: I89671\n",
      "Done for Image Data ID: I91210\n",
      "Done for Image Data ID: I89979\n",
      "Done for Image Data ID: I79085\n",
      "Done for Image Data ID: I43022\n",
      "Done for Image Data ID: I66248\n",
      "Done for Image Data ID: I46668\n",
      "Done for Image Data ID: I66436\n",
      "Done for Image Data ID: I74550\n",
      "Done for Image Data ID: I43009\n",
      "Done for Image Data ID: I66241\n",
      "Done for Image Data ID: I75128\n",
      "Done for Image Data ID: I81479\n",
      "Done for Image Data ID: I43001\n",
      "Done for Image Data ID: I66234\n",
      "Done for Image Data ID: I66230\n",
      "Done for Image Data ID: I66220\n",
      "Done for Image Data ID: I46655\n",
      "Done for Image Data ID: I46647\n",
      "Done for Image Data ID: I89103\n",
      "Done for Image Data ID: I45920\n",
      "Done for Image Data ID: I42992\n",
      "Done for Image Data ID: I89096\n",
      "Done for Image Data ID: I46629\n",
      "Done for Image Data ID: I66213\n",
      "Done for Image Data ID: I46622\n",
      "Done for Image Data ID: I79268\n",
      "Done for Image Data ID: I45910\n",
      "Done for Image Data ID: I66206\n",
      "Done for Image Data ID: I46608\n",
      "Done for Image Data ID: I45881\n",
      "Done for Image Data ID: I89089\n",
      "Done for Image Data ID: I45894\n",
      "Done for Image Data ID: I66428\n",
      "Done for Image Data ID: I67027\n",
      "Done for Image Data ID: I67275\n",
      "Done for Image Data ID: I45872\n",
      "Done for Image Data ID: I42985\n",
      "Done for Image Data ID: I66199\n",
      "Done for Image Data ID: I63838\n",
      "Done for Image Data ID: I99279\n",
      "Done for Image Data ID: I79075\n",
      "Done for Image Data ID: I85659\n",
      "Done for Image Data ID: I66815\n",
      "Done for Image Data ID: I40419\n",
      "Done for Image Data ID: I88174\n",
      "Done for Image Data ID: I89821\n",
      "Done for Image Data ID: I119737\n",
      "Done for Image Data ID: I96178\n",
      "Done for Image Data ID: I119736\n",
      "Done for Image Data ID: I72587\n",
      "Done for Image Data ID: I81463\n",
      "Done for Image Data ID: I70924\n",
      "Done for Image Data ID: I40410\n",
      "Done for Image Data ID: I67010\n",
      "Done for Image Data ID: I119734\n",
      "Done for Image Data ID: I67015\n",
      "Done for Image Data ID: I119732\n",
      "Done for Image Data ID: I66792\n",
      "Done for Image Data ID: I40387\n",
      "Done for Image Data ID: I66806\n",
      "Done for Image Data ID: I40356\n",
      "Done for Image Data ID: I119730\n",
      "Done for Image Data ID: I66778\n",
      "Done for Image Data ID: I81610\n",
      "Done for Image Data ID: I119728\n",
      "Done for Image Data ID: I66759\n",
      "Done for Image Data ID: I81601\n",
      "Done for Image Data ID: I40328\n",
      "Done for Image Data ID: I40303\n",
      "Done for Image Data ID: I119726\n",
      "Done for Image Data ID: I66745\n",
      "Done for Image Data ID: I40312\n",
      "Done for Image Data ID: I40260\n",
      "Done for Image Data ID: I63828\n",
      "Done for Image Data ID: I40292\n",
      "Done for Image Data ID: I119724\n",
      "Done for Image Data ID: I119722\n",
      "Done for Image Data ID: I81596\n",
      "Done for Image Data ID: I119720\n",
      "Done for Image Data ID: I40452\n",
      "Done for Image Data ID: I91201\n",
      "Done for Image Data ID: I119719\n",
      "Done for Image Data ID: I86097\n",
      "Done for Image Data ID: I119717\n",
      "Done for Image Data ID: I40239\n",
      "Done for Image Data ID: I66731\n",
      "Done for Image Data ID: I119716\n",
      "Done for Image Data ID: I40223\n",
      "Done for Image Data ID: I66418\n",
      "Done for Image Data ID: I119715\n",
      "Done for Image Data ID: I40201\n",
      "Done for Image Data ID: I119711\n",
      "Done for Image Data ID: I83849\n",
      "Done for Image Data ID: I88154\n",
      "Done for Image Data ID: I119713\n",
      "Done for Image Data ID: I40179\n",
      "Done for Image Data ID: I119701\n",
      "Done for Image Data ID: I66722\n",
      "Done for Image Data ID: I40445\n",
      "Done for Image Data ID: I119710\n",
      "Done for Image Data ID: I40437\n",
      "Done for Image Data ID: I88141\n",
      "Done for Image Data ID: I119678\n",
      "Done for Image Data ID: I67771\n",
      "Done for Image Data ID: I66413\n",
      "Done for Image Data ID: I119651\n",
      "Done for Image Data ID: I81583\n",
      "Done for Image Data ID: I89957\n",
      "Done for Image Data ID: I92079\n",
      "Done for Image Data ID: I119656\n",
      "Done for Image Data ID: I119654\n",
      "Done for Image Data ID: I99113\n",
      "Done for Image Data ID: I119634\n",
      "Done for Image Data ID: I119639\n",
      "Done for Image Data ID: I119636\n",
      "Done for Image Data ID: I63819\n",
      "Done for Image Data ID: I92637\n",
      "Done for Image Data ID: I119629\n",
      "Done for Image Data ID: I40000\n",
      "Done for Image Data ID: I88122\n",
      "Done for Image Data ID: I119626\n",
      "Done for Image Data ID: I119630\n",
      "Done for Image Data ID: I72565\n",
      "Done for Image Data ID: I119623\n",
      "Done for Image Data ID: I66373\n",
      "Done for Image Data ID: I81567\n",
      "Done for Image Data ID: I119622\n",
      "Done for Image Data ID: I92721\n",
      "Done for Image Data ID: I119610\n",
      "Done for Image Data ID: I92286\n",
      "Done for Image Data ID: I119602\n",
      "Done for Image Data ID: I72556\n",
      "Done for Image Data ID: I119606\n",
      "Done for Image Data ID: I91189\n",
      "Done for Image Data ID: I119604\n",
      "Done for Image Data ID: I119537\n",
      "Done for Image Data ID: I63810\n",
      "Done for Image Data ID: I90632\n",
      "Done for Image Data ID: I119534\n",
      "Done for Image Data ID: I119539\n",
      "Done for Image Data ID: I66356\n",
      "Done for Image Data ID: I119532\n",
      "Done for Image Data ID: I67531\n",
      "Done for Image Data ID: I119529\n",
      "Done for Image Data ID: I119527\n",
      "Done for Image Data ID: I81551\n",
      "Done for Image Data ID: I79053\n",
      "Done for Image Data ID: I119520\n",
      "Done for Image Data ID: I92705\n",
      "Done for Image Data ID: I119524\n",
      "Done for Image Data ID: I40954\n",
      "Done for Image Data ID: I119522\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "for data_dict in data_list:\n",
    "    image_path = f\"dip_project/preprocessed_images_3/{data_dict['Image Data ID']}.png\"\n",
    "    conversation = get_conversation(data_dict, image_path)\n",
    "    answer = get_answer(conversation)\n",
    "    classification = parse_classification(answer)\n",
    "    result_dict = {\n",
    "        \"Image Data ID\": data_dict[\"Image Data ID\"],\n",
    "        \"Classification\": classification,\n",
    "        \"Reasoning\": answer,\n",
    "    }\n",
    "    results_list.append(result_dict)\n",
    "    print(f\"Done for Image Data ID: {data_dict['Image Data ID']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76201d80-0cbf-465d-9153-a495c832e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b3e6c-ac6c-4176-83fa-863a717c96e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
