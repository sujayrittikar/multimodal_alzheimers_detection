{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9b050d-0f10-4068-8260-204bf551d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.ndimage\n",
    "from monai.networks.nets import resnet18\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4d75e-8f4a-4a7a-bfdf-197230866bdb",
   "metadata": {},
   "source": [
    "# Utility fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a590e23-3214-4ecd-8f21-55dbe1b2fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_files_with_substring(directory, substring):\n",
    "    matching_files = [f for f in os.listdir(directory) if substring in f]\n",
    "    return matching_files\n",
    "\n",
    "def get_nib_image(adni_file_name):\n",
    "    return nib.load(adni_file_name).get_fdata()\n",
    "\n",
    "def visualize_image(nib_image):\n",
    "    plt.imshow(nib_image[:,:,nib_image.shape[2]//2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14994b68-6927-4b89-b980-e4ef5611a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_file_names_for_subject(subject_id, date=None):\n",
    "    os.path.expanduser(\"~/adni_flat_dataset/adni_flat_dataset\")\n",
    "    dir_ = \"/home/rittikar-s/adni_flat_dataset/adni_flat_dataset\"\n",
    "    files = find_files_with_substring(dir_, subject_id)\n",
    "    if date:\n",
    "        files = [file for file in files if date in file]\n",
    "    file_paths = [f\"{dir_}/{file}\" for file in files]\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f471af-fd74-46dc-acbb-9b519f975a91",
   "metadata": {},
   "source": [
    "# Define 3D ViT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625f6fff-6431-4d6a-b193-d32bc4e23476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets.vitautoenc import ViTAutoEnc\n",
    "\n",
    "vit_model = ViTAutoEnc(in_channels=1, patch_size=(16,16,16), img_size=(128,128,128))\n",
    "\n",
    "def get_vit_embedding(img):\n",
    "    return vit_model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646df33-381b-41b8-ad70-d00a7eaa096e",
   "metadata": {},
   "source": [
    "# Define Nifti Dataset for ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edea833e-f78f-4fd3-8ac5-133d9db379a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, image_ids, target_shape=(128, 128, 128)):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.target_shape = target_shape\n",
    "        self.image_ids = image_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def apply_multi_bit_plane_slicing(self, img_3d, bit_planes=[6, 7]):\n",
    "        \"\"\"\n",
    "        Apply multi-bit-plane slicing to a 3D MRI image.\n",
    "        \n",
    "        Args:\n",
    "            img_3d (torch.Tensor or np.ndarray): A 3D image (shape: [depth, height, width]).\n",
    "            bit_planes (list of int): List of bit-planes to extract (0 = LSB, 7 = MSB).\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: The combined bit-plane image.\n",
    "        \"\"\"\n",
    "        X, Y, Z = img_3d.shape\n",
    "        processed_img = np.zeros_like(img_3d, dtype=np.uint8)\n",
    "        \n",
    "        if isinstance(img_3d, torch.Tensor):\n",
    "            img_3d = img_3d.cpu().numpy()  # Convert to NumPy if it's a tensor\n",
    "    \n",
    "        for z in range(Z):  # Iterate through each slice dynamically\n",
    "            slice_img = img_3d[:, :, z]  # Extract the 2D slice\n",
    "            \n",
    "            # Ensure the slice is in 8-bit format\n",
    "            slice_img = (slice_img / np.max(slice_img) * 255).astype(np.uint8)  \n",
    "            \n",
    "            bit_sliced = np.zeros_like(slice_img, dtype=np.uint8)\n",
    "    \n",
    "            # Combine selected bit planes\n",
    "            for bit in bit_planes:\n",
    "                bit_sliced |= ((slice_img >> bit) & 1) << bit  \n",
    "    \n",
    "            processed_img[:, :, z] = bit_sliced  # Store processed slice back\n",
    "    \n",
    "        return processed_img\n",
    "    \n",
    "    def preprocess_nifti(self, nifti_path, threshold_value=80):\n",
    "        # Load the NIfTI file\n",
    "        img = nib.load(nifti_path).get_fdata()\n",
    "    \n",
    "        # Resize the image to the target shape\n",
    "        img_resized = scipy.ndimage.zoom(img, np.array(self.target_shape) / np.array(img.shape), order=1)\n",
    "    \n",
    "        # Normalize intensity to [0, 1] for neural network\n",
    "        img_normalized = (img_resized - np.min(img_resized)) / (np.max(img_resized) - np.min(img_resized) + 1e-8)\n",
    "        # img_normalized = (img_normalized * 255).astype(np.uint8)  # You can adjust this based on model input needs\n",
    "    \n",
    "        # Create an empty array to store the processed result\n",
    "        processed_img = self.apply_multi_bit_plane_slicing(img_normalized, [5, 6, 7])\n",
    "    \n",
    "        # Convert the processed image to a tensor and add a channel dimension (assuming 1 channel)\n",
    "        return torch.tensor(processed_img, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.preprocess_nifti(self.image_paths[idx])\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        embedding = get_vit_embedding(image.reshape(1,1,128,128,128))\n",
    "        return embedding, label, self.image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc6588d-b228-4c3f-937f-73179615c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_image_file_for_image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ed9f65-4b7f-4ea4-a01e-895f0412f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"~/dip_project/ADNI1_Final_With_Biomarkers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93b0700-ab67-4af0-866b-92714b17fe2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>...</th>\n",
       "      <th>VISCODE_y.1</th>\n",
       "      <th>HMSCORE</th>\n",
       "      <th>VISCODE_x.2</th>\n",
       "      <th>NPISCORE</th>\n",
       "      <th>VISCODE_y.2</th>\n",
       "      <th>GDTOTAL</th>\n",
       "      <th>VISCODE2</th>\n",
       "      <th>ABETA42</th>\n",
       "      <th>TAU</th>\n",
       "      <th>PTAU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I97327</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>69</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/02/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I112538</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>m12</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>6/01/2008</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>m12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I97341</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>m06</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/27/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I63874</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>1/30/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>sc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I75150</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "      <td>m06</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>8/24/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image Data ID     Subject Group Sex  Age Visit Modality  \\\n",
       "0        I97327  941_S_1311   MCI   M   69    sc      MRI   \n",
       "1       I112538  941_S_1311   MCI   M   70   m12      MRI   \n",
       "2        I97341  941_S_1311   MCI   M   70   m06      MRI   \n",
       "3        I63874  941_S_1202    CN   M   78    sc      MRI   \n",
       "4        I75150  941_S_1202    CN   M   78   m06      MRI   \n",
       "\n",
       "                                  Description       Type   Acq Date  ...  \\\n",
       "0    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  3/02/2007  ...   \n",
       "1    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  6/01/2008  ...   \n",
       "2  MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed  9/27/2007  ...   \n",
       "3  MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed  1/30/2007  ...   \n",
       "4    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  8/24/2007  ...   \n",
       "\n",
       "  VISCODE_y.1 HMSCORE VISCODE_x.2 NPISCORE  VISCODE_y.2  GDTOTAL VISCODE2  \\\n",
       "0          sc     1.0         NaN      NaN           sc      1.0      NaN   \n",
       "1         NaN     NaN         m12      4.0          m12      3.0      NaN   \n",
       "2         NaN     NaN         m06      3.0          NaN      NaN      NaN   \n",
       "3          sc     0.0         NaN      NaN           sc      0.0      NaN   \n",
       "4         NaN     NaN         m06      2.0          NaN      NaN      NaN   \n",
       "\n",
       "   ABETA42 TAU  PTAU  \n",
       "0      NaN NaN   NaN  \n",
       "1      NaN NaN   NaN  \n",
       "2      NaN NaN   NaN  \n",
       "3      NaN NaN   NaN  \n",
       "4      NaN NaN   NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e48bb2-9233-4bc2-bda4-2f215cd8d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_label = {\n",
    "    \"CN\": 0,\n",
    "    \"MCI\": 1,\n",
    "    \"AD\": 2\n",
    "}\n",
    "image_paths = []\n",
    "labels = []\n",
    "image_ids = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    subject = row[\"Subject\"]\n",
    "    date = row[\"Acq Date\"]\n",
    "    date = date.replace(\"/\", \"-\")\n",
    "    image_id = row[\"Image Data ID\"]\n",
    "    image_path = get_image_file_names_for_subject(subject, date)[0]\n",
    "    image_paths.append(image_path)\n",
    "    image_ids.append(image_id)\n",
    "    labels.append(class_to_label[row[\"Group\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4ea626-c589-4b8b-a904-659d7156c919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f27ffb5-8eb1-45de-9309-978329415d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6045dd50-929b-430c-ab65-f8cadb216fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359985e5-ff60-4565-81cb-26fd58ac7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_paths, test_paths, train_labels, test_labels, train_image_ids, test_image_ids = train_test_split(image_paths, labels, image_ids, test_size=0.3, random_state=42, stratify=labels)\n",
    "val_paths, test_paths, val_labels, test_labels, val_image_ids, test_image_ids = train_test_split(test_paths, test_labels, test_image_ids, test_size=0.5, random_state=42, stratify=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef101c85-8bb3-44b2-8913-e8585ff6367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batches: 402, Val Batches: 86, Test Batches: 87\n"
     ]
    }
   ],
   "source": [
    "# Create train & test datasets\n",
    "train_dataset = NiftiDataset(train_paths, train_labels, train_image_ids)\n",
    "val_dataset = NiftiDataset(val_paths, val_labels, val_image_ids)\n",
    "test_dataset = NiftiDataset(test_paths, test_labels, test_image_ids)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "print(f\"Train Batches: {len(train_loader)}, Val Batches: {len(val_loader)}, Test Batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3839e01-36d3-472b-a324-bb8c37594cba",
   "metadata": {},
   "source": [
    "## ViT-BPS 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbe04ed4-f8c1-44a6-9fcc-093529f7ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_embeddings_hdf5(dataloader, filename):\n",
    "    \"\"\"Save embeddings (from list format) and labels incrementally to an HDF5 file.\"\"\"\n",
    "    with h5py.File(filename, \"w\") as f:\n",
    "        first_batch = True\n",
    "        for i, (embedding_list, label, image_id) in enumerate(dataloader):\n",
    "            # Extract the last layer embeddings\n",
    "            embedding_tensor = embedding_list[1][-1]  # Extract final layer embeddings\n",
    "            embedding_tensor = embedding_tensor.cpu().detach()  # Move to CPU\n",
    "            \n",
    "            embedding_numpy = embedding_tensor.numpy()  # Convert to NumPy\n",
    "            label_numpy = label.cpu().numpy()\n",
    "\n",
    "            # Reshape embeddings if needed\n",
    "            embedding_numpy = embedding_numpy.reshape(embedding_numpy.shape[0], -1)  # (4, 1, 512, 768) → (4, 512 * 768)\n",
    "\n",
    "            if first_batch:\n",
    "                # Create expandable datasets with correct shape\n",
    "                f.create_dataset(\"embeddings\", data=embedding_numpy, \n",
    "                                 maxshape=(None, embedding_numpy.shape[1]))  # Now 2D\n",
    "                f.create_dataset(\"labels\", data=label_numpy, maxshape=(None,))\n",
    "                first_batch = False\n",
    "            else:\n",
    "                # Resize and append new embeddings\n",
    "                f[\"embeddings\"].resize((f[\"embeddings\"].shape[0] + embedding_numpy.shape[0]), axis=0)\n",
    "                f[\"embeddings\"][-embedding_numpy.shape[0]:] = embedding_numpy\n",
    "\n",
    "                f[\"labels\"].resize((f[\"labels\"].shape[0] + label_numpy.shape[0]), axis=0)\n",
    "                f[\"labels\"][-label_numpy.shape[0]:] = label_numpy\n",
    "            \n",
    "            print(f\"Saved embeddings for batch: {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9824e3ec-1087-4468-9afe-e164b2493db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in divide\n",
      "invalid value encountered in cast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings for batch: 1\n",
      "Saved embeddings for batch: 2\n",
      "Saved embeddings for batch: 3\n",
      "Saved embeddings for batch: 4\n",
      "Saved embeddings for batch: 5\n",
      "Saved embeddings for batch: 6\n",
      "Saved embeddings for batch: 7\n",
      "Saved embeddings for batch: 8\n",
      "Saved embeddings for batch: 9\n",
      "Saved embeddings for batch: 10\n",
      "Saved embeddings for batch: 11\n",
      "Saved embeddings for batch: 12\n",
      "Saved embeddings for batch: 13\n",
      "Saved embeddings for batch: 14\n",
      "Saved embeddings for batch: 15\n",
      "Saved embeddings for batch: 16\n",
      "Saved embeddings for batch: 17\n",
      "Saved embeddings for batch: 18\n",
      "Saved embeddings for batch: 19\n",
      "Saved embeddings for batch: 20\n",
      "Saved embeddings for batch: 21\n",
      "Saved embeddings for batch: 22\n",
      "Saved embeddings for batch: 23\n",
      "Saved embeddings for batch: 24\n",
      "Saved embeddings for batch: 25\n",
      "Saved embeddings for batch: 26\n",
      "Saved embeddings for batch: 27\n",
      "Saved embeddings for batch: 28\n",
      "Saved embeddings for batch: 29\n",
      "Saved embeddings for batch: 30\n",
      "Saved embeddings for batch: 31\n",
      "Saved embeddings for batch: 32\n",
      "Saved embeddings for batch: 33\n",
      "Saved embeddings for batch: 34\n",
      "Saved embeddings for batch: 35\n",
      "Saved embeddings for batch: 36\n",
      "Saved embeddings for batch: 37\n",
      "Saved embeddings for batch: 38\n",
      "Saved embeddings for batch: 39\n",
      "Saved embeddings for batch: 40\n",
      "Saved embeddings for batch: 41\n",
      "Saved embeddings for batch: 42\n",
      "Saved embeddings for batch: 43\n",
      "Saved embeddings for batch: 44\n",
      "Saved embeddings for batch: 45\n",
      "Saved embeddings for batch: 46\n",
      "Saved embeddings for batch: 47\n",
      "Saved embeddings for batch: 48\n",
      "Saved embeddings for batch: 49\n",
      "Saved embeddings for batch: 50\n",
      "Saved embeddings for batch: 51\n",
      "Saved embeddings for batch: 52\n",
      "Saved embeddings for batch: 53\n",
      "Saved embeddings for batch: 54\n",
      "Saved embeddings for batch: 55\n",
      "Saved embeddings for batch: 56\n",
      "Saved embeddings for batch: 57\n",
      "Saved embeddings for batch: 58\n",
      "Saved embeddings for batch: 59\n",
      "Saved embeddings for batch: 60\n",
      "Saved embeddings for batch: 61\n",
      "Saved embeddings for batch: 62\n",
      "Saved embeddings for batch: 63\n",
      "Saved embeddings for batch: 64\n",
      "Saved embeddings for batch: 65\n",
      "Saved embeddings for batch: 66\n",
      "Saved embeddings for batch: 67\n",
      "Saved embeddings for batch: 68\n",
      "Saved embeddings for batch: 69\n",
      "Saved embeddings for batch: 70\n",
      "Saved embeddings for batch: 71\n",
      "Saved embeddings for batch: 72\n",
      "Saved embeddings for batch: 73\n",
      "Saved embeddings for batch: 74\n",
      "Saved embeddings for batch: 75\n",
      "Saved embeddings for batch: 76\n",
      "Saved embeddings for batch: 77\n",
      "Saved embeddings for batch: 78\n",
      "Saved embeddings for batch: 79\n",
      "Saved embeddings for batch: 80\n",
      "Saved embeddings for batch: 81\n",
      "Saved embeddings for batch: 82\n",
      "Saved embeddings for batch: 83\n",
      "Saved embeddings for batch: 84\n",
      "Saved embeddings for batch: 85\n",
      "Saved embeddings for batch: 86\n",
      "Saved embeddings for batch: 87\n",
      "Saved embeddings for batch: 88\n",
      "Saved embeddings for batch: 89\n",
      "Saved embeddings for batch: 90\n",
      "Saved embeddings for batch: 91\n",
      "Saved embeddings for batch: 92\n",
      "Saved embeddings for batch: 93\n",
      "Saved embeddings for batch: 94\n",
      "Saved embeddings for batch: 95\n",
      "Saved embeddings for batch: 96\n",
      "Saved embeddings for batch: 97\n",
      "Saved embeddings for batch: 98\n",
      "Saved embeddings for batch: 99\n",
      "Saved embeddings for batch: 100\n",
      "Saved embeddings for batch: 101\n",
      "Saved embeddings for batch: 102\n",
      "Saved embeddings for batch: 103\n",
      "Saved embeddings for batch: 104\n",
      "Saved embeddings for batch: 105\n",
      "Saved embeddings for batch: 106\n",
      "Saved embeddings for batch: 107\n",
      "Saved embeddings for batch: 108\n",
      "Saved embeddings for batch: 109\n",
      "Saved embeddings for batch: 110\n",
      "Saved embeddings for batch: 111\n",
      "Saved embeddings for batch: 112\n",
      "Saved embeddings for batch: 113\n",
      "Saved embeddings for batch: 114\n",
      "Saved embeddings for batch: 115\n",
      "Saved embeddings for batch: 116\n",
      "Saved embeddings for batch: 117\n",
      "Saved embeddings for batch: 118\n",
      "Saved embeddings for batch: 119\n",
      "Saved embeddings for batch: 120\n",
      "Saved embeddings for batch: 121\n",
      "Saved embeddings for batch: 122\n",
      "Saved embeddings for batch: 123\n",
      "Saved embeddings for batch: 124\n",
      "Saved embeddings for batch: 125\n",
      "Saved embeddings for batch: 126\n",
      "Saved embeddings for batch: 127\n",
      "Saved embeddings for batch: 128\n",
      "Saved embeddings for batch: 129\n",
      "Saved embeddings for batch: 130\n",
      "Saved embeddings for batch: 131\n",
      "Saved embeddings for batch: 132\n",
      "Saved embeddings for batch: 133\n",
      "Saved embeddings for batch: 134\n",
      "Saved embeddings for batch: 135\n",
      "Saved embeddings for batch: 136\n",
      "Saved embeddings for batch: 137\n",
      "Saved embeddings for batch: 138\n",
      "Saved embeddings for batch: 139\n",
      "Saved embeddings for batch: 140\n",
      "Saved embeddings for batch: 141\n",
      "Saved embeddings for batch: 142\n",
      "Saved embeddings for batch: 143\n",
      "Saved embeddings for batch: 144\n",
      "Saved embeddings for batch: 145\n",
      "Saved embeddings for batch: 146\n",
      "Saved embeddings for batch: 147\n",
      "Saved embeddings for batch: 148\n",
      "Saved embeddings for batch: 149\n",
      "Saved embeddings for batch: 150\n",
      "Saved embeddings for batch: 151\n",
      "Saved embeddings for batch: 152\n",
      "Saved embeddings for batch: 153\n",
      "Saved embeddings for batch: 154\n",
      "Saved embeddings for batch: 155\n",
      "Saved embeddings for batch: 156\n",
      "Saved embeddings for batch: 157\n",
      "Saved embeddings for batch: 158\n",
      "Saved embeddings for batch: 159\n",
      "Saved embeddings for batch: 160\n",
      "Saved embeddings for batch: 161\n",
      "Saved embeddings for batch: 162\n",
      "Saved embeddings for batch: 163\n",
      "Saved embeddings for batch: 164\n",
      "Saved embeddings for batch: 165\n",
      "Saved embeddings for batch: 166\n",
      "Saved embeddings for batch: 167\n",
      "Saved embeddings for batch: 168\n",
      "Saved embeddings for batch: 169\n",
      "Saved embeddings for batch: 170\n",
      "Saved embeddings for batch: 171\n",
      "Saved embeddings for batch: 172\n",
      "Saved embeddings for batch: 173\n",
      "Saved embeddings for batch: 174\n",
      "Saved embeddings for batch: 175\n",
      "Saved embeddings for batch: 176\n",
      "Saved embeddings for batch: 177\n",
      "Saved embeddings for batch: 178\n",
      "Saved embeddings for batch: 179\n",
      "Saved embeddings for batch: 180\n",
      "Saved embeddings for batch: 181\n",
      "Saved embeddings for batch: 182\n",
      "Saved embeddings for batch: 183\n",
      "Saved embeddings for batch: 184\n",
      "Saved embeddings for batch: 185\n",
      "Saved embeddings for batch: 186\n",
      "Saved embeddings for batch: 187\n",
      "Saved embeddings for batch: 188\n",
      "Saved embeddings for batch: 189\n",
      "Saved embeddings for batch: 190\n",
      "Saved embeddings for batch: 191\n",
      "Saved embeddings for batch: 192\n",
      "Saved embeddings for batch: 193\n",
      "Saved embeddings for batch: 194\n",
      "Saved embeddings for batch: 195\n",
      "Saved embeddings for batch: 196\n",
      "Saved embeddings for batch: 197\n",
      "Saved embeddings for batch: 198\n",
      "Saved embeddings for batch: 199\n",
      "Saved embeddings for batch: 200\n",
      "Saved embeddings for batch: 201\n",
      "Saved embeddings for batch: 202\n",
      "Saved embeddings for batch: 203\n",
      "Saved embeddings for batch: 204\n",
      "Saved embeddings for batch: 205\n",
      "Saved embeddings for batch: 206\n",
      "Saved embeddings for batch: 207\n",
      "Saved embeddings for batch: 208\n",
      "Saved embeddings for batch: 209\n",
      "Saved embeddings for batch: 210\n",
      "Saved embeddings for batch: 211\n",
      "Saved embeddings for batch: 212\n",
      "Saved embeddings for batch: 213\n",
      "Saved embeddings for batch: 214\n",
      "Saved embeddings for batch: 215\n",
      "Saved embeddings for batch: 216\n",
      "Saved embeddings for batch: 217\n",
      "Saved embeddings for batch: 218\n",
      "Saved embeddings for batch: 219\n",
      "Saved embeddings for batch: 220\n",
      "Saved embeddings for batch: 221\n",
      "Saved embeddings for batch: 222\n",
      "Saved embeddings for batch: 223\n",
      "Saved embeddings for batch: 224\n",
      "Saved embeddings for batch: 225\n",
      "Saved embeddings for batch: 226\n",
      "Saved embeddings for batch: 227\n",
      "Saved embeddings for batch: 228\n",
      "Saved embeddings for batch: 229\n",
      "Saved embeddings for batch: 230\n",
      "Saved embeddings for batch: 231\n",
      "Saved embeddings for batch: 232\n",
      "Saved embeddings for batch: 233\n",
      "Saved embeddings for batch: 234\n",
      "Saved embeddings for batch: 235\n",
      "Saved embeddings for batch: 236\n",
      "Saved embeddings for batch: 237\n",
      "Saved embeddings for batch: 238\n",
      "Saved embeddings for batch: 239\n",
      "Saved embeddings for batch: 240\n",
      "Saved embeddings for batch: 241\n",
      "Saved embeddings for batch: 242\n",
      "Saved embeddings for batch: 243\n",
      "Saved embeddings for batch: 244\n",
      "Saved embeddings for batch: 245\n",
      "Saved embeddings for batch: 246\n",
      "Saved embeddings for batch: 247\n",
      "Saved embeddings for batch: 248\n",
      "Saved embeddings for batch: 249\n",
      "Saved embeddings for batch: 250\n",
      "Saved embeddings for batch: 251\n",
      "Saved embeddings for batch: 252\n",
      "Saved embeddings for batch: 253\n",
      "Saved embeddings for batch: 254\n",
      "Saved embeddings for batch: 255\n",
      "Saved embeddings for batch: 256\n",
      "Saved embeddings for batch: 257\n",
      "Saved embeddings for batch: 258\n",
      "Saved embeddings for batch: 259\n",
      "Saved embeddings for batch: 260\n",
      "Saved embeddings for batch: 261\n",
      "Saved embeddings for batch: 262\n",
      "Saved embeddings for batch: 263\n",
      "Saved embeddings for batch: 264\n",
      "Saved embeddings for batch: 265\n",
      "Saved embeddings for batch: 266\n",
      "Saved embeddings for batch: 267\n",
      "Saved embeddings for batch: 268\n",
      "Saved embeddings for batch: 269\n",
      "Saved embeddings for batch: 270\n",
      "Saved embeddings for batch: 271\n",
      "Saved embeddings for batch: 272\n",
      "Saved embeddings for batch: 273\n",
      "Saved embeddings for batch: 274\n",
      "Saved embeddings for batch: 275\n",
      "Saved embeddings for batch: 276\n",
      "Saved embeddings for batch: 277\n",
      "Saved embeddings for batch: 278\n",
      "Saved embeddings for batch: 279\n",
      "Saved embeddings for batch: 280\n",
      "Saved embeddings for batch: 281\n",
      "Saved embeddings for batch: 282\n",
      "Saved embeddings for batch: 283\n",
      "Saved embeddings for batch: 284\n",
      "Saved embeddings for batch: 285\n",
      "Saved embeddings for batch: 286\n",
      "Saved embeddings for batch: 287\n",
      "Saved embeddings for batch: 288\n",
      "Saved embeddings for batch: 289\n",
      "Saved embeddings for batch: 290\n",
      "Saved embeddings for batch: 291\n",
      "Saved embeddings for batch: 292\n",
      "Saved embeddings for batch: 293\n",
      "Saved embeddings for batch: 294\n",
      "Saved embeddings for batch: 295\n",
      "Saved embeddings for batch: 296\n",
      "Saved embeddings for batch: 297\n",
      "Saved embeddings for batch: 298\n",
      "Saved embeddings for batch: 299\n",
      "Saved embeddings for batch: 300\n",
      "Saved embeddings for batch: 301\n",
      "Saved embeddings for batch: 302\n",
      "Saved embeddings for batch: 303\n",
      "Saved embeddings for batch: 304\n",
      "Saved embeddings for batch: 305\n",
      "Saved embeddings for batch: 306\n",
      "Saved embeddings for batch: 307\n",
      "Saved embeddings for batch: 308\n",
      "Saved embeddings for batch: 309\n",
      "Saved embeddings for batch: 310\n",
      "Saved embeddings for batch: 311\n",
      "Saved embeddings for batch: 312\n",
      "Saved embeddings for batch: 313\n",
      "Saved embeddings for batch: 314\n",
      "Saved embeddings for batch: 315\n",
      "Saved embeddings for batch: 316\n",
      "Saved embeddings for batch: 317\n",
      "Saved embeddings for batch: 318\n",
      "Saved embeddings for batch: 319\n",
      "Saved embeddings for batch: 320\n",
      "Saved embeddings for batch: 321\n",
      "Saved embeddings for batch: 322\n",
      "Saved embeddings for batch: 323\n",
      "Saved embeddings for batch: 324\n",
      "Saved embeddings for batch: 325\n",
      "Saved embeddings for batch: 326\n",
      "Saved embeddings for batch: 327\n",
      "Saved embeddings for batch: 328\n",
      "Saved embeddings for batch: 329\n",
      "Saved embeddings for batch: 330\n",
      "Saved embeddings for batch: 331\n",
      "Saved embeddings for batch: 332\n",
      "Saved embeddings for batch: 333\n",
      "Saved embeddings for batch: 334\n",
      "Saved embeddings for batch: 335\n",
      "Saved embeddings for batch: 336\n",
      "Saved embeddings for batch: 337\n",
      "Saved embeddings for batch: 338\n",
      "Saved embeddings for batch: 339\n",
      "Saved embeddings for batch: 340\n",
      "Saved embeddings for batch: 341\n",
      "Saved embeddings for batch: 342\n",
      "Saved embeddings for batch: 343\n",
      "Saved embeddings for batch: 344\n",
      "Saved embeddings for batch: 345\n",
      "Saved embeddings for batch: 346\n",
      "Saved embeddings for batch: 347\n",
      "Saved embeddings for batch: 348\n",
      "Saved embeddings for batch: 349\n",
      "Saved embeddings for batch: 350\n",
      "Saved embeddings for batch: 351\n",
      "Saved embeddings for batch: 352\n",
      "Saved embeddings for batch: 353\n",
      "Saved embeddings for batch: 354\n",
      "Saved embeddings for batch: 355\n",
      "Saved embeddings for batch: 356\n",
      "Saved embeddings for batch: 357\n",
      "Saved embeddings for batch: 358\n",
      "Saved embeddings for batch: 359\n",
      "Saved embeddings for batch: 360\n",
      "Saved embeddings for batch: 361\n",
      "Saved embeddings for batch: 362\n",
      "Saved embeddings for batch: 363\n",
      "Saved embeddings for batch: 364\n",
      "Saved embeddings for batch: 365\n",
      "Saved embeddings for batch: 366\n",
      "Saved embeddings for batch: 367\n",
      "Saved embeddings for batch: 368\n",
      "Saved embeddings for batch: 369\n",
      "Saved embeddings for batch: 370\n",
      "Saved embeddings for batch: 371\n",
      "Saved embeddings for batch: 372\n",
      "Saved embeddings for batch: 373\n",
      "Saved embeddings for batch: 374\n",
      "Saved embeddings for batch: 375\n",
      "Saved embeddings for batch: 376\n",
      "Saved embeddings for batch: 377\n",
      "Saved embeddings for batch: 378\n",
      "Saved embeddings for batch: 379\n",
      "Saved embeddings for batch: 380\n",
      "Saved embeddings for batch: 381\n",
      "Saved embeddings for batch: 382\n",
      "Saved embeddings for batch: 383\n",
      "Saved embeddings for batch: 384\n",
      "Saved embeddings for batch: 385\n",
      "Saved embeddings for batch: 386\n",
      "Saved embeddings for batch: 387\n",
      "Saved embeddings for batch: 388\n",
      "Saved embeddings for batch: 389\n",
      "Saved embeddings for batch: 390\n",
      "Saved embeddings for batch: 391\n",
      "Saved embeddings for batch: 392\n",
      "Saved embeddings for batch: 393\n",
      "Saved embeddings for batch: 394\n",
      "Saved embeddings for batch: 395\n",
      "Saved embeddings for batch: 396\n",
      "Saved embeddings for batch: 397\n",
      "Saved embeddings for batch: 398\n",
      "Saved embeddings for batch: 399\n",
      "Saved embeddings for batch: 400\n",
      "Saved embeddings for batch: 401\n",
      "Saved embeddings for batch: 402\n",
      "Saved embeddings for batch: 1\n",
      "Saved embeddings for batch: 2\n",
      "Saved embeddings for batch: 3\n",
      "Saved embeddings for batch: 4\n",
      "Saved embeddings for batch: 5\n",
      "Saved embeddings for batch: 6\n",
      "Saved embeddings for batch: 7\n",
      "Saved embeddings for batch: 8\n",
      "Saved embeddings for batch: 9\n",
      "Saved embeddings for batch: 10\n",
      "Saved embeddings for batch: 11\n",
      "Saved embeddings for batch: 12\n",
      "Saved embeddings for batch: 13\n",
      "Saved embeddings for batch: 14\n",
      "Saved embeddings for batch: 15\n",
      "Saved embeddings for batch: 16\n",
      "Saved embeddings for batch: 17\n",
      "Saved embeddings for batch: 18\n",
      "Saved embeddings for batch: 19\n",
      "Saved embeddings for batch: 20\n",
      "Saved embeddings for batch: 21\n",
      "Saved embeddings for batch: 22\n",
      "Saved embeddings for batch: 23\n",
      "Saved embeddings for batch: 24\n",
      "Saved embeddings for batch: 25\n",
      "Saved embeddings for batch: 26\n",
      "Saved embeddings for batch: 27\n",
      "Saved embeddings for batch: 28\n",
      "Saved embeddings for batch: 29\n",
      "Saved embeddings for batch: 30\n",
      "Saved embeddings for batch: 31\n",
      "Saved embeddings for batch: 32\n",
      "Saved embeddings for batch: 33\n",
      "Saved embeddings for batch: 34\n",
      "Saved embeddings for batch: 35\n",
      "Saved embeddings for batch: 36\n",
      "Saved embeddings for batch: 37\n",
      "Saved embeddings for batch: 38\n",
      "Saved embeddings for batch: 39\n",
      "Saved embeddings for batch: 40\n",
      "Saved embeddings for batch: 41\n",
      "Saved embeddings for batch: 42\n",
      "Saved embeddings for batch: 43\n",
      "Saved embeddings for batch: 44\n",
      "Saved embeddings for batch: 45\n",
      "Saved embeddings for batch: 46\n",
      "Saved embeddings for batch: 47\n",
      "Saved embeddings for batch: 48\n",
      "Saved embeddings for batch: 49\n",
      "Saved embeddings for batch: 50\n",
      "Saved embeddings for batch: 51\n",
      "Saved embeddings for batch: 52\n",
      "Saved embeddings for batch: 53\n",
      "Saved embeddings for batch: 54\n",
      "Saved embeddings for batch: 55\n",
      "Saved embeddings for batch: 56\n",
      "Saved embeddings for batch: 57\n",
      "Saved embeddings for batch: 58\n",
      "Saved embeddings for batch: 59\n",
      "Saved embeddings for batch: 60\n",
      "Saved embeddings for batch: 61\n",
      "Saved embeddings for batch: 62\n",
      "Saved embeddings for batch: 63\n",
      "Saved embeddings for batch: 64\n",
      "Saved embeddings for batch: 65\n",
      "Saved embeddings for batch: 66\n",
      "Saved embeddings for batch: 67\n",
      "Saved embeddings for batch: 68\n",
      "Saved embeddings for batch: 69\n",
      "Saved embeddings for batch: 70\n",
      "Saved embeddings for batch: 71\n",
      "Saved embeddings for batch: 72\n",
      "Saved embeddings for batch: 73\n",
      "Saved embeddings for batch: 74\n",
      "Saved embeddings for batch: 75\n",
      "Saved embeddings for batch: 76\n",
      "Saved embeddings for batch: 77\n",
      "Saved embeddings for batch: 78\n",
      "Saved embeddings for batch: 79\n",
      "Saved embeddings for batch: 80\n",
      "Saved embeddings for batch: 81\n",
      "Saved embeddings for batch: 82\n",
      "Saved embeddings for batch: 83\n",
      "Saved embeddings for batch: 84\n",
      "Saved embeddings for batch: 85\n",
      "Saved embeddings for batch: 86\n",
      "Saved embeddings for batch: 1\n",
      "Saved embeddings for batch: 2\n",
      "Saved embeddings for batch: 3\n",
      "Saved embeddings for batch: 4\n",
      "Saved embeddings for batch: 5\n",
      "Saved embeddings for batch: 6\n",
      "Saved embeddings for batch: 7\n",
      "Saved embeddings for batch: 8\n",
      "Saved embeddings for batch: 9\n",
      "Saved embeddings for batch: 10\n",
      "Saved embeddings for batch: 11\n",
      "Saved embeddings for batch: 12\n",
      "Saved embeddings for batch: 13\n",
      "Saved embeddings for batch: 14\n",
      "Saved embeddings for batch: 15\n",
      "Saved embeddings for batch: 16\n",
      "Saved embeddings for batch: 17\n",
      "Saved embeddings for batch: 18\n",
      "Saved embeddings for batch: 19\n",
      "Saved embeddings for batch: 20\n",
      "Saved embeddings for batch: 21\n",
      "Saved embeddings for batch: 22\n",
      "Saved embeddings for batch: 23\n",
      "Saved embeddings for batch: 24\n",
      "Saved embeddings for batch: 25\n",
      "Saved embeddings for batch: 26\n",
      "Saved embeddings for batch: 27\n",
      "Saved embeddings for batch: 28\n",
      "Saved embeddings for batch: 29\n",
      "Saved embeddings for batch: 30\n",
      "Saved embeddings for batch: 31\n",
      "Saved embeddings for batch: 32\n",
      "Saved embeddings for batch: 33\n",
      "Saved embeddings for batch: 34\n",
      "Saved embeddings for batch: 35\n",
      "Saved embeddings for batch: 36\n",
      "Saved embeddings for batch: 37\n",
      "Saved embeddings for batch: 38\n",
      "Saved embeddings for batch: 39\n",
      "Saved embeddings for batch: 40\n",
      "Saved embeddings for batch: 41\n",
      "Saved embeddings for batch: 42\n",
      "Saved embeddings for batch: 43\n",
      "Saved embeddings for batch: 44\n",
      "Saved embeddings for batch: 45\n",
      "Saved embeddings for batch: 46\n",
      "Saved embeddings for batch: 47\n",
      "Saved embeddings for batch: 48\n",
      "Saved embeddings for batch: 49\n",
      "Saved embeddings for batch: 50\n",
      "Saved embeddings for batch: 51\n",
      "Saved embeddings for batch: 52\n",
      "Saved embeddings for batch: 53\n",
      "Saved embeddings for batch: 54\n",
      "Saved embeddings for batch: 55\n",
      "Saved embeddings for batch: 56\n",
      "Saved embeddings for batch: 57\n",
      "Saved embeddings for batch: 58\n",
      "Saved embeddings for batch: 59\n",
      "Saved embeddings for batch: 60\n",
      "Saved embeddings for batch: 61\n",
      "Saved embeddings for batch: 62\n",
      "Saved embeddings for batch: 63\n",
      "Saved embeddings for batch: 64\n",
      "Saved embeddings for batch: 65\n",
      "Saved embeddings for batch: 66\n",
      "Saved embeddings for batch: 67\n",
      "Saved embeddings for batch: 68\n",
      "Saved embeddings for batch: 69\n",
      "Saved embeddings for batch: 70\n",
      "Saved embeddings for batch: 71\n",
      "Saved embeddings for batch: 72\n",
      "Saved embeddings for batch: 73\n",
      "Saved embeddings for batch: 74\n",
      "Saved embeddings for batch: 75\n",
      "Saved embeddings for batch: 76\n",
      "Saved embeddings for batch: 77\n",
      "Saved embeddings for batch: 78\n",
      "Saved embeddings for batch: 79\n",
      "Saved embeddings for batch: 80\n",
      "Saved embeddings for batch: 81\n",
      "Saved embeddings for batch: 82\n",
      "Saved embeddings for batch: 83\n",
      "Saved embeddings for batch: 84\n",
      "Saved embeddings for batch: 85\n",
      "Saved embeddings for batch: 86\n",
      "Saved embeddings for batch: 87\n"
     ]
    }
   ],
   "source": [
    "save_embeddings_hdf5(train_loader, \"train_embeddings.h5\")\n",
    "save_embeddings_hdf5(val_loader, \"val_embeddings.h5\")\n",
    "save_embeddings_hdf5(test_loader, \"test_embeddings.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "306a7921-dc54-4587-a32d-41ca92423a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0a7bc8e-8275-4108-ab15-d5eeeb7aece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_hdf5(filename, batch_size=4):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        num_samples = f[\"embeddings\"].shape[0]  # Total samples\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            X_batch = torch.tensor(f[\"embeddings\"][i : i + batch_size], dtype=torch.float32).to(DEVICE)\n",
    "            y_batch = torch.tensor(f[\"labels\"][i : i + batch_size], dtype=torch.long).to(DEVICE)\n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "454d5d1f-0916-4440-9dc2-b93cb1094725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(1024)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(256, num_classes)  # Final layer\n",
    "\n",
    "    def forward(self, x, return_embeddings=False):\n",
    "        x = self.fc1(x)\n",
    "        if x.shape[0] > 1:  # Apply BatchNorm only if batch size > 1\n",
    "            x = self.batch_norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "    \n",
    "        x = self.fc2(x)\n",
    "        if x.shape[0] > 1:\n",
    "            x = self.batch_norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "    \n",
    "        x = self.fc3(x)\n",
    "        if x.shape[0] > 1:\n",
    "            x = self.batch_norm3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        if return_embeddings:\n",
    "            return x\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5893a67-ed0f-4a19-acb8-1f6f0e95e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = next(load_embeddings_hdf5(\"train_embeddings.h5\"))[0].shape[1]  # Get feature size\n",
    "num_classes = 3  # Adjust based on labels\n",
    "model = MLPClassifier(input_dim, num_classes).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8fdaee5-e901-4d99-a941-77f09a625400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (fc1): Linear(in_features=393216, out_features=1024, bias=True)\n",
       "  (batch_norm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (batch_norm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (batch_norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       "  (fc4): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "924f2d6e-fb34-4d92-ae1f-92b66eff4bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.                         | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 1/100 Train: 101it [00:11,  8.58it/s, acc=35, loss=1.18]                                                                                              \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.01it/s, acc=49.1, loss=0.995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\n",
      "  Train Loss: 0.0729 | Train Acc: 35.02%\n",
      "  Val Loss: 0.0662 | Val Acc: 49.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Train: 101it [00:11,  8.65it/s, acc=43.7, loss=1.03]                                                                                            \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.59it/s, acc=51.5, loss=0.962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100]\n",
      "  Train Loss: 0.0670 | Train Acc: 43.68%\n",
      "  Val Loss: 0.0652 | Val Acc: 51.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Train: 101it [00:11,  8.66it/s, acc=50.2, loss=0.693]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.63it/s, acc=56.7, loss=0.928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100]\n",
      "  Train Loss: 0.0628 | Train Acc: 50.22%\n",
      "  Val Loss: 0.0637 | Val Acc: 56.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Train: 101it [00:11,  8.64it/s, acc=55.1, loss=0.923]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.87it/s, acc=58.7, loss=0.848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100]\n",
      "  Train Loss: 0.0596 | Train Acc: 55.14%\n",
      "  Val Loss: 0.0623 | Val Acc: 58.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Train: 101it [00:11,  8.65it/s, acc=58.8, loss=0.923]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.61it/s, acc=60.2, loss=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100]\n",
      "  Train Loss: 0.0575 | Train Acc: 58.75%\n",
      "  Val Loss: 0.0613 | Val Acc: 60.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Train: 101it [00:11,  8.65it/s, acc=64.4, loss=0.666]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 53.37it/s, acc=63.1, loss=0.805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100]\n",
      "  Train Loss: 0.0528 | Train Acc: 64.36%\n",
      "  Val Loss: 0.0602 | Val Acc: 63.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Train: 101it [00:11,  8.66it/s, acc=67.8, loss=0.634]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.22it/s, acc=63.4, loss=0.788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100]\n",
      "  Train Loss: 0.0504 | Train Acc: 67.79%\n",
      "  Val Loss: 0.0590 | Val Acc: 63.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 Train: 101it [00:11,  8.64it/s, acc=72.5, loss=0.574]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.53it/s, acc=63.1, loss=0.729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100]\n",
      "  Train Loss: 0.0470 | Train Acc: 72.46%\n",
      "  Val Loss: 0.0582 | Val Acc: 63.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 Train: 101it [00:11,  8.65it/s, acc=74.8, loss=0.579]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.71it/s, acc=62.5, loss=0.742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100]\n",
      "  Train Loss: 0.0441 | Train Acc: 74.83%\n",
      "  Val Loss: 0.0577 | Val Acc: 62.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 Train: 101it [00:11,  8.68it/s, acc=79.6, loss=0.49]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.04it/s, acc=61.9, loss=0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100]\n",
      "  Train Loss: 0.0399 | Train Acc: 79.63%\n",
      "  Val Loss: 0.0569 | Val Acc: 61.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 Train: 101it [00:11,  8.64it/s, acc=82.9, loss=0.463]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.88it/s, acc=62.8, loss=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100]\n",
      "  Train Loss: 0.0369 | Train Acc: 82.93%\n",
      "  Val Loss: 0.0562 | Val Acc: 62.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 Train: 101it [00:11,  8.68it/s, acc=85.6, loss=0.305]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.67it/s, acc=64, loss=0.653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100]\n",
      "  Train Loss: 0.0343 | Train Acc: 85.61%\n",
      "  Val Loss: 0.0548 | Val Acc: 63.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 Train: 101it [00:11,  8.67it/s, acc=89.9, loss=0.505]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.91it/s, acc=63.1, loss=0.646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100]\n",
      "  Train Loss: 0.0300 | Train Acc: 89.91%\n",
      "  Val Loss: 0.0540 | Val Acc: 63.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 Train: 101it [00:11,  8.65it/s, acc=89.9, loss=0.284]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.01it/s, acc=63.1, loss=0.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100]\n",
      "  Train Loss: 0.0285 | Train Acc: 89.91%\n",
      "  Val Loss: 0.0531 | Val Acc: 63.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 Train: 101it [00:11,  8.66it/s, acc=93.1, loss=0.212]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.25it/s, acc=64.2, loss=0.548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100]\n",
      "  Train Loss: 0.0255 | Train Acc: 93.15%\n",
      "  Val Loss: 0.0521 | Val Acc: 64.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 Train: 101it [00:11,  8.66it/s, acc=93.2, loss=0.188]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.15it/s, acc=64, loss=0.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100]\n",
      "  Train Loss: 0.0235 | Train Acc: 93.21%\n",
      "  Val Loss: 0.0518 | Val Acc: 63.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 Train: 101it [00:11,  8.63it/s, acc=94.4, loss=0.296]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 53.59it/s, acc=65.4, loss=0.509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100]\n",
      "  Train Loss: 0.0216 | Train Acc: 94.39%\n",
      "  Val Loss: 0.0510 | Val Acc: 65.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 Train: 101it [00:11,  8.65it/s, acc=96.2, loss=0.198]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 51.92it/s, acc=66, loss=0.455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100]\n",
      "  Train Loss: 0.0185 | Train Acc: 96.20%\n",
      "  Val Loss: 0.0509 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 Train: 101it [00:11,  8.65it/s, acc=96.6, loss=0.229]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.26it/s, acc=66.3, loss=0.452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100]\n",
      "  Train Loss: 0.0168 | Train Acc: 96.57%\n",
      "  Val Loss: 0.0503 | Val Acc: 66.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 Train: 101it [00:11,  8.64it/s, acc=98.1, loss=0.155]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.68it/s, acc=65.7, loss=0.446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100]\n",
      "  Train Loss: 0.0152 | Train Acc: 98.07%\n",
      "  Val Loss: 0.0499 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 Train: 101it [00:11,  8.65it/s, acc=97.6, loss=0.184]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.94it/s, acc=64.8, loss=0.463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100]\n",
      "  Train Loss: 0.0142 | Train Acc: 97.63%\n",
      "  Val Loss: 0.0499 | Val Acc: 64.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 Train: 101it [00:11,  8.65it/s, acc=98.6, loss=0.091]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.55it/s, acc=63.7, loss=0.468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100]\n",
      "  Train Loss: 0.0128 | Train Acc: 98.63%\n",
      "  Val Loss: 0.0496 | Val Acc: 63.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 Train: 101it [00:11,  8.66it/s, acc=99.1, loss=0.0808]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 53.48it/s, acc=64.8, loss=0.429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100]\n",
      "  Train Loss: 0.0113 | Train Acc: 99.07%\n",
      "  Val Loss: 0.0502 | Val Acc: 64.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 Train: 101it [00:11,  8.65it/s, acc=99.1, loss=0.128]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.94it/s, acc=63.7, loss=0.409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100]\n",
      "  Train Loss: 0.0109 | Train Acc: 99.13%\n",
      "  Val Loss: 0.0501 | Val Acc: 63.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 Train: 101it [00:11,  8.67it/s, acc=99, loss=0.0783]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.18it/s, acc=66.3, loss=0.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100]\n",
      "  Train Loss: 0.0101 | Train Acc: 99.00%\n",
      "  Val Loss: 0.0491 | Val Acc: 66.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 Train: 101it [00:11,  8.64it/s, acc=99.6, loss=0.0647]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.91it/s, acc=67.2, loss=0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100]\n",
      "  Train Loss: 0.0090 | Train Acc: 99.56%\n",
      "  Val Loss: 0.0493 | Val Acc: 67.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 Train: 101it [00:11,  8.64it/s, acc=99.4, loss=0.1]                                                                                            \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 52.16it/s, acc=66, loss=0.445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100]\n",
      "  Train Loss: 0.0084 | Train Acc: 99.44%\n",
      "  Val Loss: 0.0496 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 Train: 101it [00:11,  8.66it/s, acc=99.6, loss=0.121]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.12it/s, acc=65.7, loss=0.472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100]\n",
      "  Train Loss: 0.0078 | Train Acc: 99.56%\n",
      "  Val Loss: 0.0493 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 Train: 101it [00:11,  8.61it/s, acc=99.6, loss=0.103]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 51.19it/s, acc=66, loss=0.445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100]\n",
      "  Train Loss: 0.0071 | Train Acc: 99.63%\n",
      "  Val Loss: 0.0494 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 Train: 101it [00:11,  8.66it/s, acc=99.6, loss=0.0539]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.38it/s, acc=65.7, loss=0.488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100]\n",
      "  Train Loss: 0.0071 | Train Acc: 99.56%\n",
      "  Val Loss: 0.0500 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 Train: 101it [00:11,  8.63it/s, acc=99.7, loss=0.11]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.06it/s, acc=66.6, loss=0.458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100]\n",
      "  Train Loss: 0.0066 | Train Acc: 99.69%\n",
      "  Val Loss: 0.0502 | Val Acc: 66.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 Train: 101it [00:11,  8.64it/s, acc=99.6, loss=0.0603]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.40it/s, acc=65.4, loss=0.466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100]\n",
      "  Train Loss: 0.0061 | Train Acc: 99.63%\n",
      "  Val Loss: 0.0497 | Val Acc: 65.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 Train: 101it [00:11,  8.65it/s, acc=99.8, loss=0.0372]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.64it/s, acc=65.7, loss=0.425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100]\n",
      "  Train Loss: 0.0058 | Train Acc: 99.81%\n",
      "  Val Loss: 0.0498 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 Train: 101it [00:11,  8.64it/s, acc=99.8, loss=0.0414]                                                                                         \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.41it/s, acc=65.7, loss=0.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100]\n",
      "  Train Loss: 0.0055 | Train Acc: 99.81%\n",
      "  Val Loss: 0.0501 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 Train: 101it [00:11,  8.64it/s, acc=99.8, loss=0.0199]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 53.48it/s, acc=66.6, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100]\n",
      "  Train Loss: 0.0053 | Train Acc: 99.75%\n",
      "  Val Loss: 0.0501 | Val Acc: 66.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 Train: 101it [00:11,  8.66it/s, acc=99.9, loss=0.0709]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.26it/s, acc=66.3, loss=0.457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100]\n",
      "  Train Loss: 0.0051 | Train Acc: 99.88%\n",
      "  Val Loss: 0.0501 | Val Acc: 66.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 Train: 101it [00:11,  8.69it/s, acc=99.7, loss=0.0576]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.67it/s, acc=66.3, loss=0.441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100]\n",
      "  Train Loss: 0.0050 | Train Acc: 99.69%\n",
      "  Val Loss: 0.0502 | Val Acc: 66.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 Train: 101it [00:11,  8.63it/s, acc=99.9, loss=0.0293]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.87it/s, acc=66.6, loss=0.441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100]\n",
      "  Train Loss: 0.0048 | Train Acc: 99.88%\n",
      "  Val Loss: 0.0502 | Val Acc: 66.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 Train: 101it [00:11,  8.66it/s, acc=99.9, loss=0.0639]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.48it/s, acc=66.3, loss=0.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100]\n",
      "  Train Loss: 0.0047 | Train Acc: 99.88%\n",
      "  Val Loss: 0.0502 | Val Acc: 66.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 Train: 101it [00:11,  8.72it/s, acc=99.9, loss=0.0489]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.77it/s, acc=66.9, loss=0.438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 40. No improvement in validation loss for 15 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # Progress tracking\n",
    "\n",
    "# Compute class weights\n",
    "def compute_class_weights(y_train):\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    return torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "y_train = np.concatenate([y.cpu().numpy() for _, y in load_embeddings_hdf5(\"train_embeddings.h5\", batch_size=32)])\n",
    "class_weights = compute_class_weights(y_train)\n",
    "\n",
    "# Define optimizer, scheduler, and scaler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "NUM_GPUS = 1\n",
    "num_epochs = 100\n",
    "patience = 15  # Early stopping patience\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    # Training loop\n",
    "    train_loader = load_embeddings_hdf5(\"train_embeddings.h5\", batch_size=16 * NUM_GPUS)  # Adjust batch size\n",
    "    train_bar = tqdm(train_loader, total=len(y_train) // (16 * NUM_GPUS), desc=f\"Epoch {epoch+1}/{num_epochs} Train\")\n",
    "    for X_batch, y_batch in train_bar:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():  # Mixed precision\n",
    "            outputs = model(X_batch)\n",
    "            loss = F.cross_entropy(outputs, y_batch)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "        \n",
    "        train_bar.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    avg_train_loss = train_loss / total\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    val_loader = load_embeddings_hdf5(\"val_embeddings.h5\", batch_size=16 * NUM_GPUS)\n",
    "    val_bar = tqdm(val_loader, total=len(y_train) // (16 * NUM_GPUS), desc=\"Validation\")\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_bar:\n",
    "            X_val, y_val = X_val.to(DEVICE), y_val.to(DEVICE)\n",
    "            outputs = model(X_val)\n",
    "            loss = F.cross_entropy(outputs, y_val)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(y_val).sum().item()\n",
    "            val_total += y_val.size(0)\n",
    "\n",
    "            val_bar.set_postfix(loss=loss.item(), acc=100 * val_correct / val_total)\n",
    "    \n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    avg_val_loss = val_loss / val_total\n",
    "\n",
    "    # Check for early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Stop if no improvement for 10 epochs\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}. No improvement in validation loss for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "    # Learning rate scheduler step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}%\")\n",
    "    print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef362a5c-3271-4f4c-8e1f-3b29571e4686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6261\n",
      "Precision: 0.6283\n",
      "Recall: 0.6261\n",
      "F1 Score: 0.6091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Inference\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in load_embeddings_hdf5(\"test_embeddings.h5\", batch_size=4):\n",
    "        outputs = model(X_batch)\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(y_batch.cpu().numpy())\n",
    "        y_pred.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average=\"weighted\")  # \"weighted\" accounts for class imbalance\n",
    "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fc12a0a-7d6d-46d0-be55-c6df76fccd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58       106\n",
      "           1       0.62      0.82      0.70       167\n",
      "           2       0.62      0.33      0.43        72\n",
      "\n",
      "    accuracy                           0.63       345\n",
      "   macro avg       0.63      0.56      0.57       345\n",
      "weighted avg       0.63      0.63      0.61       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe391a-8c1c-490b-a217-265c05ffa703",
   "metadata": {},
   "source": [
    "# Ft-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa55cabb-f78c-4115-9f3e-bec17bb550f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Import the FTTransformer model from rtdl_revisiting_models.\n",
    "from rtdl_revisiting_models import FTTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04359373-96ff-4b17-8994-b1bd66717abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\"Age\", \"CDGLOBAL\", \"CDRSB\", \"MMSCORE\", \"HMSCORE\", \"NPISCORE\", \"GDTOTAL\"]\n",
    "categorical_features = [\"GENOTYPE\"]\n",
    "label = \"Group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b20fc4b8-a569-4781-b5b0-b433569f1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset dataframes to desired columns.\n",
    "cols = numerical_features + categorical_features + [label]\n",
    "train_data = df[df[\"Image Data ID\"].isin(train_image_ids)][cols]\n",
    "val_data   = df[df[\"Image Data ID\"].isin(val_image_ids)][cols]\n",
    "test_data  = df[df[\"Image Data ID\"].isin(test_image_ids)][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed319a7a-e64c-46cf-83ac-524c04cba3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data.csv\")\n",
    "val_data.to_csv(\"val_data.csv\")\n",
    "test_data.to_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4abf4e06-7323-4b68-a493-f6aeb06c3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missingness for numerical features.\n",
    "cols_with_missing = [\"CDRSB\", \"MMSCORE\", \"HMSCORE\", \"NPISCORE\", \"GDTOTAL\"]\n",
    "for col in cols_with_missing:\n",
    "    for df_ in [train_data, val_data, test_data]:\n",
    "        df_[col + \"_is_missing\"] = df_[col].isnull().astype(int)\n",
    "        df_[col] = df_[col].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c75ffe1a-91d7-424f-b826-8d690f734f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend continuous features to include missing indicators.\n",
    "numerical_features_extended = numerical_features + [col + \"_is_missing\" for col in cols_with_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ce9180f-8a61-4bf6-a215-3758515b385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features using LabelEncoder.\n",
    "cat_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col].astype(str))\n",
    "    val_data[col]   = le.transform(val_data[col].astype(str))\n",
    "    test_data[col]  = le.transform(test_data[col].astype(str))\n",
    "    cat_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f62442a8-c34a-47fd-8ead-dbc5fc2f0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target.\n",
    "label_encoder = LabelEncoder()\n",
    "train_data[label] = label_encoder.fit_transform(train_data[label])\n",
    "val_data[label]   = label_encoder.transform(val_data[label])\n",
    "test_data[label]  = label_encoder.transform(test_data[label])\n",
    "num_classes = len(label_encoder.classes_)  # e.g., 3 for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c987242c-df36-454b-bb9e-4eeb5300d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# 2. Prepare NumPy Arrays and Create Dataset\n",
    "##########################################\n",
    "# Continuous features (including missing indicators).\n",
    "X_train_cont = train_data[numerical_features_extended].values.astype(np.float32)\n",
    "X_val_cont   = val_data[numerical_features_extended].values.astype(np.float32)\n",
    "X_test_cont  = test_data[numerical_features_extended].values.astype(np.float32)\n",
    "\n",
    "# Categorical features.\n",
    "X_train_cat = train_data[categorical_features].values.astype(np.int64)\n",
    "X_val_cat   = val_data[categorical_features].values.astype(np.int64)\n",
    "X_test_cat  = test_data[categorical_features].values.astype(np.int64)\n",
    "\n",
    "# Labels.\n",
    "y_train = train_data[label].values.astype(np.int64)\n",
    "y_val   = val_data[label].values.astype(np.int64)\n",
    "y_test  = test_data[label].values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d007cd7a-03b3-48bd-b48c-03eb6ffcb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple PyTorch Dataset.\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, cont, cat, labels):\n",
    "        self.cont = cont\n",
    "        self.cat = cat\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"cont\": torch.tensor(self.cont[idx], dtype=torch.float32),\n",
    "            \"cat\": torch.tensor(self.cat[idx], dtype=torch.long),\n",
    "            \"target\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e30a47c-42f0-4341-a109-b8b54c76a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TabularDataset(X_train_cont, X_train_cat, y_train)\n",
    "val_dataset   = TabularDataset(X_val_cont, X_val_cat, y_val)\n",
    "test_dataset  = TabularDataset(X_test_cont, X_test_cat, y_test)\n",
    "\n",
    "# Create DataLoaders.\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5d34477-b7ca-4390-8ba8-1736a446d80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FTTransformer(\n",
       "  (cls_embedding): _CLSEmbedding()\n",
       "  (cont_embeddings): LinearEmbeddings()\n",
       "  (cat_embeddings): CategoricalEmbeddings(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(6, 192)\n",
       "    )\n",
       "  )\n",
       "  (backbone): FTTransformerBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (linear1): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): _ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "      )\n",
       "      (1-2): 2 x ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (linear1): Linear(in_features=192, out_features=512, bias=True)\n",
       "          (activation): _ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=192, bias=True)\n",
       "        )\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (output): Sequential(\n",
       "      (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): ReLU()\n",
       "      (linear): Linear(in_features=192, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "# 3. Initialize and Train the FTTransformer Classifier\n",
    "##########################################\n",
    "# Get the number of continuous features.\n",
    "n_cont_features = X_train_cont.shape[1]\n",
    "# Determine the cardinalities for each categorical feature.\n",
    "cat_cardinalities = [int(train_data[col].nunique()) for col in categorical_features]\n",
    "\n",
    "# For classification, set d_out = number of classes.\n",
    "d_out = num_classes\n",
    "\n",
    "# Instantiate the FTTransformer.\n",
    "model = FTTransformer(\n",
    "    n_cont_features=n_cont_features,\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    d_out=d_out,\n",
    "    n_blocks=3,\n",
    "    d_block=192,                # Backbone (hidden) dimension\n",
    "    attention_n_heads=8,\n",
    "    attention_dropout=0.2,\n",
    "    ffn_d_hidden=None,          # Defaults internally if None.\n",
    "    ffn_d_hidden_multiplier=4/3,\n",
    "    ffn_dropout=0.1,\n",
    "    residual_dropout=0.0\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6936dfa6-cea3-4bba-accb-5207983568ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.0597 | Val Loss: 1.0601\n",
      "Epoch 2: Train Loss: 1.0354 | Val Loss: 0.9883\n",
      "Epoch 3: Train Loss: 0.8518 | Val Loss: 0.6626\n",
      "Epoch 4: Train Loss: 0.5633 | Val Loss: 0.3959\n",
      "Epoch 5: Train Loss: 0.4657 | Val Loss: 0.3652\n",
      "Epoch 6: Train Loss: 0.4325 | Val Loss: 0.3221\n",
      "Epoch 7: Train Loss: 0.3945 | Val Loss: 0.3015\n",
      "Epoch 8: Train Loss: 0.3642 | Val Loss: 0.3225\n",
      "Epoch 9: Train Loss: 0.3462 | Val Loss: 0.3173\n",
      "Epoch 10: Train Loss: 0.3730 | Val Loss: 0.3152\n",
      "Epoch 11: Train Loss: 0.3429 | Val Loss: 0.3154\n",
      "Epoch 12: Train Loss: 0.3237 | Val Loss: 0.2893\n",
      "Epoch 13: Train Loss: 0.3101 | Val Loss: 0.2754\n",
      "Epoch 14: Train Loss: 0.3139 | Val Loss: 0.2796\n",
      "Epoch 15: Train Loss: 0.3050 | Val Loss: 0.2958\n",
      "Epoch 16: Train Loss: 0.3178 | Val Loss: 0.3067\n",
      "Epoch 17: Train Loss: 0.3099 | Val Loss: 0.2720\n",
      "Epoch 18: Train Loss: 0.3074 | Val Loss: 0.2764\n",
      "Epoch 19: Train Loss: 0.2993 | Val Loss: 0.2811\n",
      "Epoch 20: Train Loss: 0.3157 | Val Loss: 0.2752\n",
      "Epoch 21: Train Loss: 0.3014 | Val Loss: 0.2794\n",
      "Epoch 22: Train Loss: 0.2945 | Val Loss: 0.2761\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# Set up optimizer, loss function, and scheduler.\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "# Training loop with early stopping.\n",
    "max_epochs = 100\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        cont = batch[\"cont\"].to(device)\n",
    "        cat = batch[\"cat\"].to(device)\n",
    "        targets = batch[\"target\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(cont, cat)  # Forward pass returns logits (shape: [batch_size, d_out])\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * cont.size(0)\n",
    "    train_loss /= len(train_dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            cont = batch[\"cont\"].to(device)\n",
    "            cat = batch[\"cat\"].to(device)\n",
    "            targets = batch[\"target\"].to(device)\n",
    "            \n",
    "            logits = model(cont, cat)\n",
    "            loss = criterion(logits, targets)\n",
    "            val_loss += loss.item() * cont.size(0)\n",
    "    val_loss /= len(val_dataset)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0fa1398-6026-43f2-b114-66dc0e52cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved to best_ft_transformer_classification.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the best model.\n",
    "save_model_path = \"best_ft_transformer_classification.pt\"\n",
    "torch.save(best_model_state, save_model_path)\n",
    "print(\"Trained model saved to\", save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00095974-4e72-4b70-adde-cc91eba669a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model (optional).\n",
    "model.load_state_dict(torch.load(save_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a05d2d5-a620-489f-b83e-6327ed0cd865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8405797101449275\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.70      0.60      0.65        72\n",
      "          CN       0.96      0.95      0.96       106\n",
      "         MCI       0.82      0.87      0.84       167\n",
      "\n",
      "    accuracy                           0.84       345\n",
      "   macro avg       0.83      0.81      0.82       345\n",
      "weighted avg       0.84      0.84      0.84       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classification performance on the test set.\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        cont = batch[\"cont\"].to(device)\n",
    "        cat = batch[\"cat\"].to(device)\n",
    "        targets = batch[\"target\"].to(device)\n",
    "        \n",
    "        logits = model(cont, cat)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "test_acc = accuracy_score(all_targets, all_preds)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Classification Report (Test):\")\n",
    "print(classification_report(all_targets, all_preds, target_names=[str(c) for c in label_encoder.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "054ff1df-bc5b-4641-913e-4d0e34747df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature shapes:\n",
      "Train features: (1605, 3)\n",
      "Validation features: (344, 3)\n",
      "Test features: (345, 3)\n",
      "Extracted features saved as 'ft_train_features.npy', 'ft_val_features.npy', and 'ft_test_features.npy'.\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# 4. Extract 192-Dimensional Embeddings (Before the Final Classification)\n",
    "##########################################\n",
    "# The classifier was trained with d_out = num_classes.\n",
    "# To obtain 192-dim embeddings (the backbone outputs), we replace the final linear layer with an identity.\n",
    "# Here we assume the final projection is stored in the attribute 'fc'.\n",
    "model.fc = nn.Identity()  # Now model(cont, cat) returns the backbone features of shape (batch_size, 192).\n",
    "\n",
    "# Function to extract features from a DataLoader.\n",
    "def extract_features(loader, model, device):\n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            cont = batch[\"cont\"].to(device)\n",
    "            cat = batch[\"cat\"].to(device)\n",
    "            feats = model(cont, cat)  # Should now return features of shape (batch_size, 192)\n",
    "            features_list.append(feats.cpu().numpy())\n",
    "    return np.concatenate(features_list)\n",
    "\n",
    "# Extract features from each set.\n",
    "features_train = extract_features(train_loader, model, device)\n",
    "features_val   = extract_features(val_loader, model, device)\n",
    "features_test  = extract_features(test_loader, model, device)\n",
    "\n",
    "print(\"Extracted feature shapes:\")\n",
    "print(\"Train features:\", features_train.shape)\n",
    "print(\"Validation features:\", features_val.shape)\n",
    "print(\"Test features:\", features_test.shape)\n",
    "\n",
    "# Save the extracted features.\n",
    "np.save(\"ft_train_features.npy\", features_train)\n",
    "np.save(\"ft_val_features.npy\", features_val)\n",
    "np.save(\"ft_test_features.npy\", features_test)\n",
    "print(\"Extracted features saved as 'ft_train_features.npy', 'ft_val_features.npy', and 'ft_test_features.npy'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dab0b1-76a8-4a1f-ab4e-faf9e85e10f9",
   "metadata": {},
   "source": [
    "# Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73bf6fa9-ddfd-4990-9b54-43de9ebcfd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def load_embeddings_hdf5_np(filename):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        embeddings = f[\"embeddings\"][:].astype(np.float32)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a7893c7-7a1f-4227-bfdc-6023afcfd37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = load_embeddings_hdf5_np(\"train_embeddings.h5\")\n",
    "val_features   = load_embeddings_hdf5_np(\"val_embeddings.h5\")\n",
    "test_features  = load_embeddings_hdf5_np(\"test_embeddings.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41e9f9a5-11bf-4c4e-a494-f06f9ba88b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1605, 393216)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c9a380a-2ea9-4f1f-b1ed-58739e64b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_train = np.load(\"ft_train_features.npy\")  # shape: (num_train_samples, ft_feature_dim)\n",
    "ft_val   = np.load(\"ft_val_features.npy\")      # shape: (num_val_samples,   ft_feature_dim)\n",
    "ft_test  = np.load(\"ft_test_features.npy\")     # shape: (num_test_samples,  ft_feature_dim)\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Concatenate DeiT features with TabNet embeddings\n",
    "# -------------------------------------------------------------------\n",
    "train_concat = np.concatenate([ft_train, train_features], axis=1)\n",
    "val_concat   = np.concatenate([ft_val,   val_features],   axis=1)\n",
    "test_concat  = np.concatenate([ft_test,  test_features],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "810249f6-d52b-4540-af42-604e9ed15692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenated Train Shape: (1605, 393219)\n",
      "Concatenated Val Shape:   (344, 393219)\n",
      "Concatenated Test Shape:  (345, 393219)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConcatenated Train Shape:\", train_concat.shape)\n",
    "print(\"Concatenated Val Shape:  \", val_concat.shape)\n",
    "print(\"Concatenated Test Shape: \", test_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95e9d630-b7ec-4d96-a8b0-e22f1654937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# We assume the label column is named \"Group\"\n",
    "label_col = \"Group\"\n",
    "\n",
    "# Encode labels using LabelEncoder.\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_data[label_col])\n",
    "val_labels   = label_encoder.transform(val_data[label_col])\n",
    "test_labels  = label_encoder.transform(test_data[label_col])\n",
    "\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "505c74ee-2a8e-438a-ac85-d87acc23626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "##########################################\n",
    "# 3. Create PyTorch Datasets and DataLoaders\n",
    "##########################################\n",
    "# Convert features and labels to tensors.\n",
    "train_concat = torch.tensor(train_concat, dtype=torch.float32)\n",
    "val_concat   = torch.tensor(val_concat, dtype=torch.float32)\n",
    "test_concat  = torch.tensor(test_concat, dtype=torch.float32)\n",
    "\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "val_labels   = torch.tensor(val_labels, dtype=torch.long)\n",
    "test_labels  = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets.\n",
    "train_dataset = TensorDataset(train_concat, train_labels)\n",
    "val_dataset   = TensorDataset(val_concat, val_labels)\n",
    "test_dataset  = TensorDataset(test_concat, test_labels)\n",
    "\n",
    "# Create DataLoaders.\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b3b86e4-839d-4846-a638-99cce232dde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=393219, out_features=2048, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Dropout(p=0.1, inplace=False)\n",
       "    (7): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): LeakyReLU(negative_slope=0.01)\n",
       "    (10): Dropout(p=0.1, inplace=False)\n",
       "    (11): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): LeakyReLU(negative_slope=0.01)\n",
       "    (14): Dropout(p=0.1, inplace=False)\n",
       "    (15): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "# 4. Define an MLP Classifier for Fused Features\n",
    "##########################################\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),  # Increased first layer size\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),  # BatchNorm starts here\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# The input dimension is the sum of the two feature dimensions.\n",
    "input_dim = train_concat.shape[1]\n",
    "model_mlp = MLPClassifier(input_dim, num_classes)\n",
    "model_mlp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3e4d743-0725-4fda-998c-6d05ef084da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Train Loss = 1.0930, Val Acc = 0.4797\n",
      "Epoch 2/50: Train Loss = 1.0628, Val Acc = 0.4244\n",
      "Epoch 3/50: Train Loss = 1.0507, Val Acc = 0.4360\n",
      "Epoch 4/50: Train Loss = 1.0129, Val Acc = 0.4419\n",
      "Epoch 5/50: Train Loss = 0.9632, Val Acc = 0.3779\n",
      "Epoch 6/50: Train Loss = 0.8950, Val Acc = 0.3779\n",
      "Epoch 7/50: Train Loss = 0.8005, Val Acc = 0.3779\n",
      "Epoch 8/50: Train Loss = 0.7174, Val Acc = 0.3983\n",
      "Epoch 9/50: Train Loss = 0.6405, Val Acc = 0.3198\n",
      "Epoch 10/50: Train Loss = 0.5782, Val Acc = 0.3779\n",
      "Epoch 11/50: Train Loss = 0.5126, Val Acc = 0.3605\n",
      "Epoch 12/50: Train Loss = 0.4780, Val Acc = 0.2645\n",
      "Epoch 13/50: Train Loss = 0.4443, Val Acc = 0.3750\n",
      "Epoch 14/50: Train Loss = 0.4350, Val Acc = 0.3488\n",
      "Epoch 15/50: Train Loss = 0.3975, Val Acc = 0.4244\n",
      "Epoch 16/50: Train Loss = 0.3879, Val Acc = 0.3808\n",
      "Epoch 17/50: Train Loss = 0.3754, Val Acc = 0.3663\n",
      "Epoch 18/50: Train Loss = 0.3884, Val Acc = 0.3517\n",
      "Epoch 19/50: Train Loss = 0.3151, Val Acc = 0.3169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 18\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataset)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate on the validation set.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# 5. Train the MLP Classifier\n",
    "##########################################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_mlp.parameters(), lr=1e-3)\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_mlp.train()\n",
    "    train_loss = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model_mlp(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    train_loss /= len(train_dataset)\n",
    "    \n",
    "    # Evaluate on the validation set.\n",
    "    model_mlp.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model_mlp(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    val_acc = accuracy_score(all_targets, all_preds)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.4f}, Val Acc = {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
