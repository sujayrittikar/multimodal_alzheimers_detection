{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639b83ad-d5da-4086-8727-0aaa02dd4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585fc6dd-9cee-4632-96e2-5fb9f2194fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/dip_project/ADNI1_Final_With_Biomarkers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a40213-1a5f-4fe8-a081-207e37b55d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>...</th>\n",
       "      <th>VISCODE_y.1</th>\n",
       "      <th>HMSCORE</th>\n",
       "      <th>VISCODE_x.2</th>\n",
       "      <th>NPISCORE</th>\n",
       "      <th>VISCODE_y.2</th>\n",
       "      <th>GDTOTAL</th>\n",
       "      <th>VISCODE2</th>\n",
       "      <th>ABETA42</th>\n",
       "      <th>TAU</th>\n",
       "      <th>PTAU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I97327</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>69</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/02/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I112538</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>m12</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>6/01/2008</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>m12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I97341</td>\n",
       "      <td>941_S_1311</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>m06</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/27/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I63874</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>1/30/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>sc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I75150</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "      <td>m06</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n",
       "      <td>Processed</td>\n",
       "      <td>8/24/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image Data ID     Subject Group Sex  Age Visit Modality  \\\n",
       "0        I97327  941_S_1311   MCI   M   69    sc      MRI   \n",
       "1       I112538  941_S_1311   MCI   M   70   m12      MRI   \n",
       "2        I97341  941_S_1311   MCI   M   70   m06      MRI   \n",
       "3        I63874  941_S_1202    CN   M   78    sc      MRI   \n",
       "4        I75150  941_S_1202    CN   M   78   m06      MRI   \n",
       "\n",
       "                                  Description       Type   Acq Date  ...  \\\n",
       "0    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  3/02/2007  ...   \n",
       "1    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  6/01/2008  ...   \n",
       "2  MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed  9/27/2007  ...   \n",
       "3  MPR-R; GradWarp; B1 Correction; N3; Scaled  Processed  1/30/2007  ...   \n",
       "4    MPR; GradWarp; B1 Correction; N3; Scaled  Processed  8/24/2007  ...   \n",
       "\n",
       "  VISCODE_y.1 HMSCORE VISCODE_x.2 NPISCORE  VISCODE_y.2  GDTOTAL VISCODE2  \\\n",
       "0          sc     1.0         NaN      NaN           sc      1.0      NaN   \n",
       "1         NaN     NaN         m12      4.0          m12      3.0      NaN   \n",
       "2         NaN     NaN         m06      3.0          NaN      NaN      NaN   \n",
       "3          sc     0.0         NaN      NaN           sc      0.0      NaN   \n",
       "4         NaN     NaN         m06      2.0          NaN      NaN      NaN   \n",
       "\n",
       "   ABETA42 TAU  PTAU  \n",
       "0      NaN NaN   NaN  \n",
       "1      NaN NaN   NaN  \n",
       "2      NaN NaN   NaN  \n",
       "3      NaN NaN   NaN  \n",
       "4      NaN NaN   NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5437f4-7459-47f8-a6c6-a45b505906db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Image Data ID', 'Subject', 'Group', 'Sex', 'Age', 'Visit', 'Modality',\n",
       "       'Description', 'Type', 'Acq Date', 'Format', 'Downloaded', 'GENOTYPE',\n",
       "       'VISCODE_x', 'CDGLOBAL', 'CDRSB', 'VISCODE_y', 'MMSCORE', 'VISCODE_x.1',\n",
       "       'TOTAL11', 'TOTALMOD', 'VISCODE_y.1', 'HMSCORE', 'VISCODE_x.2',\n",
       "       'NPISCORE', 'VISCODE_y.2', 'GDTOTAL', 'VISCODE2', 'ABETA42', 'TAU',\n",
       "       'PTAU'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078e2c3d-392b-47cd-aa73-bffe38ca9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "train_data, temp_data = train_test_split(df, test_size=(1 - train_ratio), random_state=42, stratify=df[\"Group\"])\n",
    "val_data, test_data = train_test_split(temp_data, test_size=(test_ratio / (test_ratio + val_ratio)), random_state=42, stratify=temp_data[\"Group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d935416c-6ad7-43b7-a6f5-6903177eded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed:\n",
      "Training set: 1605 samples\n",
      "Validation set: 344 samples\n",
      "Test set: 345 samples\n"
     ]
    }
   ],
   "source": [
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "val_data.to_csv(\"val_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "print(f\"Data split completed:\")\n",
    "print(f\"Training set: {len(train_data)} samples\")\n",
    "print(f\"Validation set: {len(val_data)} samples\")\n",
    "print(f\"Test set: {len(test_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f5cd0f-7fe5-4346-b851-700414281a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6dd521c-ddff-48a9-bb0c-bfa1cd1ebc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Age\", \"GENOTYPE\", \"CDGLOBAL\", \"CDRSB\", \"MMSCORE\", \"HMSCORE\", \"NPISCORE\", \"GDTOTAL\"]\n",
    "label = \"Group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ef2e6b-6a2e-41e6-a804-0bf2ab6fa737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[features + [label]]\n",
    "val_data   = val_data[features + [label]]\n",
    "test_data  = test_data[features + [label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a864669b-a9d3-4065-acc3-6c1d0d4407f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [\"CDRSB\", \"MMSCORE\", \"HMSCORE\", \"NPISCORE\", \"GDTOTAL\"]\n",
    "for col in cols_with_missing:\n",
    "    for df in [train_data, val_data, test_data]:\n",
    "        # Optionally create a missingness indicator (if needed)\n",
    "        df[col + \"_is_missing\"] = df[col].isnull().astype(int)\n",
    "        # Replace NaNs with a sentinel value (-999)\n",
    "        df[col] = df[col].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a63b398-0ffa-4bf1-b31a-2555e9d06172",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# 4. Encode GENOTYPE using one-hot encoding and align columns\n",
    "##############################\n",
    "# Process training data first as reference.\n",
    "train_data[\"GENOTYPE\"] = train_data[\"GENOTYPE\"].astype(str)\n",
    "train_data = pd.get_dummies(train_data, columns=[\"GENOTYPE\"], prefix=\"geno\")\n",
    "# Save the training DataFrame columns (this includes feature and label columns)\n",
    "train_cols = train_data.columns\n",
    "\n",
    "# Process validation data and reindex to match training columns\n",
    "val_data[\"GENOTYPE\"] = val_data[\"GENOTYPE\"].astype(str)\n",
    "val_data = pd.get_dummies(val_data, columns=[\"GENOTYPE\"], prefix=\"geno\")\n",
    "val_data = val_data.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "# Process test data similarly\n",
    "test_data[\"GENOTYPE\"] = test_data[\"GENOTYPE\"].astype(str)\n",
    "test_data = pd.get_dummies(test_data, columns=[\"GENOTYPE\"], prefix=\"geno\")\n",
    "test_data = test_data.reindex(columns=train_cols, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e8bdef0-c7dc-46fc-a68a-6fbdfaad99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# 5. Separate features (X) and label (y)\n",
    "##############################\n",
    "# Now all splits have the same set of columns.\n",
    "X_train = train_data.drop(columns=[label])\n",
    "y_train = train_data[label].values\n",
    "\n",
    "X_val = val_data.drop(columns=[label])\n",
    "y_val = val_data[label].values\n",
    "\n",
    "X_test = test_data.drop(columns=[label])\n",
    "y_test = test_data[label].values\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val   = label_encoder.transform(y_val)\n",
    "y_test  = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1be75ca-0236-4989-83e9-ce3b8bc765c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (1605, 18)\n",
      "Val size: (344, 18)\n",
      "Test size: (345, 18)\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# 6. (Optional) Print dataset sizes\n",
    "##############################\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Val size:\", X_val.shape)\n",
    "print(\"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b53de038-fa36-4ae0-b794-8c7e93325e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rittikar-s/miniconda3/envs/myenv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# 7. Define the TabNet Classifier\n",
    "##############################\n",
    "model = TabNetClassifier(\n",
    "    n_d=8,\n",
    "    n_a=8,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-3),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    scheduler_params={\"mode\": \"min\", \"patience\": 3, \"factor\": 0.5, \"verbose\": True},\n",
    "    mask_type=\"sparsemax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35231b0a-ed40-47c7-a3bf-731437d9f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# 8. Convert data to NumPy arrays and force numeric type\n",
    "##############################\n",
    "# Convert DataFrames to NumPy arrays (only feature columns) as float32.\n",
    "X_train_np = X_train.astype(np.float32).values\n",
    "X_val_np   = X_val.astype(np.float32).values\n",
    "X_test_np  = X_test.astype(np.float32).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67015f9f-e8d1-4c87-9e1f-b239c578617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rittikar-s/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.19343 | val_logloss: 1.15953 |  0:00:01s\n",
      "epoch 1  | loss: 0.98    | val_logloss: 1.03577 |  0:00:02s\n",
      "epoch 2  | loss: 0.87469 | val_logloss: 0.97525 |  0:00:03s\n",
      "epoch 3  | loss: 0.74449 | val_logloss: 0.92245 |  0:00:04s\n",
      "epoch 4  | loss: 0.65337 | val_logloss: 0.83739 |  0:00:05s\n",
      "epoch 5  | loss: 0.58243 | val_logloss: 0.74631 |  0:00:06s\n",
      "epoch 6  | loss: 0.52134 | val_logloss: 0.74027 |  0:00:07s\n",
      "epoch 7  | loss: 0.47344 | val_logloss: 0.74848 |  0:00:08s\n",
      "epoch 8  | loss: 0.46673 | val_logloss: 0.68043 |  0:00:09s\n",
      "epoch 9  | loss: 0.4512  | val_logloss: 0.6004  |  0:00:10s\n",
      "epoch 10 | loss: 0.42788 | val_logloss: 0.5807  |  0:00:11s\n",
      "epoch 11 | loss: 0.46408 | val_logloss: 0.55405 |  0:00:12s\n",
      "epoch 12 | loss: 0.37881 | val_logloss: 0.52739 |  0:00:14s\n",
      "epoch 13 | loss: 0.40812 | val_logloss: 0.52026 |  0:00:15s\n",
      "epoch 14 | loss: 0.40162 | val_logloss: 0.48909 |  0:00:16s\n",
      "epoch 15 | loss: 0.39168 | val_logloss: 0.50959 |  0:00:17s\n",
      "epoch 16 | loss: 0.38038 | val_logloss: 0.53457 |  0:00:18s\n",
      "epoch 17 | loss: 0.38802 | val_logloss: 0.52796 |  0:00:19s\n",
      "epoch 18 | loss: 0.38844 | val_logloss: 0.49836 |  0:00:20s\n",
      "epoch 19 | loss: 0.36826 | val_logloss: 0.50151 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_logloss = 0.48909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rittikar-s/miniconda3/envs/myenv/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# 9. Train with Early Stopping\n",
    "##############################\n",
    "model.fit(\n",
    "    X_train=X_train_np, y_train=y_train,\n",
    "    eval_set=[(X_val_np, y_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=[\"logloss\"],\n",
    "    max_epochs=100,\n",
    "    patience=5,\n",
    "    batch_size=32,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2162d0f-10e3-4980-a0bd-a0a3888df037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at best_tabnet_model_1.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best_tabnet_model_1.zip'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "# 10. Save the best model\n",
    "##############################\n",
    "save_model_path = \"best_tabnet_model_1\"\n",
    "model.save_model(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4b973a2-729b-4e2d-afe3-f6d5c8676634",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# 11. Load the saved model (optional)\n",
    "##############################\n",
    "model.load_model(save_model_path + \".zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d864ccaf-d961-445c-aa2e-bbc2b665b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       1.00      0.14      0.24        72\n",
      "          CN       0.98      0.95      0.97       106\n",
      "         MCI       0.71      0.99      0.83       167\n",
      "\n",
      "    accuracy                           0.80       345\n",
      "   macro avg       0.90      0.69      0.68       345\n",
      "weighted avg       0.85      0.80      0.75       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# 12. Evaluate on Test Set\n",
    "##############################\n",
    "y_pred = model.predict(X_test_np)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Classification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred, target_names=[str(c) for c in label_encoder.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "504fc1f5-418a-49e6-afea-bb27baaa7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, X_np):\n",
    "    \"\"\"\n",
    "    Extract intermediate embeddings from a trained TabNetClassifier.\n",
    "    \n",
    "    This function registers a forward hook on the final mapping of the underlying \n",
    "    TabNet (stored in model.network.tabnet.final_mapping) to capture its input, which\n",
    "    is considered the learned embedding, during a forward pass.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TabNetClassifier\n",
    "        A trained TabNet model.\n",
    "    X_np : np.array\n",
    "        Input data as a NumPy array.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    embeddings_array : np.array\n",
    "        Extracted embeddings for all samples.\n",
    "    \"\"\"\n",
    "    # Set the underlying network to evaluation mode.\n",
    "    model.network.eval()\n",
    "    \n",
    "    embeddings_list = []\n",
    "    \n",
    "    # Define a hook function that captures the input to the final mapping.\n",
    "    def hook_fn(module, input, output):\n",
    "        # input[0] is the tensor entering the final mapping layer.\n",
    "        embeddings_list.append(input[0].detach().cpu().numpy())\n",
    "    \n",
    "    # Register the hook on the final mapping layer.\n",
    "    hook_handle = model.network.tabnet.final_mapping.register_forward_hook(hook_fn)\n",
    "    \n",
    "    # Run a forward pass over X_np.\n",
    "    _ = model.predict(X_np)\n",
    "    \n",
    "    # Remove the hook.\n",
    "    hook_handle.remove()\n",
    "    \n",
    "    # Concatenate the embeddings from all batches.\n",
    "    embeddings_array = np.concatenate(embeddings_list, axis=0)\n",
    "    return embeddings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be77304a-5839-41a4-8a09-82816873e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape: (1605, 8)\n",
      "Validation embeddings shape: (344, 8)\n",
      "Test embeddings shape: (345, 8)\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = extract_embeddings(model, X_train_np)\n",
    "val_embeddings   = extract_embeddings(model, X_val_np)\n",
    "test_embeddings  = extract_embeddings(model, X_test_np)\n",
    "\n",
    "print(\"Train embeddings shape:\", train_embeddings_3.shape)\n",
    "print(\"Validation embeddings shape:\", val_embeddings_3.shape)\n",
    "print(\"Test embeddings shape:\", test_embeddings_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f9e479e-2a48-4f0b-a840-7bbd772f751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_embeddings.npy\", train_embeddings)\n",
    "np.save(\"val_embeddings.npy\", val_embeddings)\n",
    "np.save(\"test_embeddings.npy\", test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5ab27db-baf3-4143-9574-c645f2d49f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8425b86b-194c-49f3-a1ae-67945ded77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_tensor = torch.tensor(train_embeddings_3, dtype=torch.float32)\n",
    "val_emb_tensor   = torch.tensor(val_embeddings_3, dtype=torch.float32)\n",
    "test_emb_tensor  = torch.tensor(test_embeddings_3, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67f28b08-1d60-4b36-ae2a-bc489a1fb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val_tensor   = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test_tensor  = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a2d9bc4-70df-4785-bd7a-b469eff4a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets and DataLoaders.\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(train_emb_tensor, y_train_tensor)\n",
    "val_dataset   = TensorDataset(val_emb_tensor, y_val_tensor)\n",
    "test_dataset  = TensorDataset(test_emb_tensor, y_test_tensor)\n",
    "\n",
    "train_loader_mlp = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_mlp   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader_mlp  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1154c719-b62e-427b-9d2c-2532953b15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple MLP model.\n",
    "class EmbeddingMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(EmbeddingMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c26f1daf-6f12-4e68-8819-1b0cf109c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_embeddings.shape[1]  # For example, 32\n",
    "hidden_dim = 64\n",
    "num_classes = len(np.unique(y_train))\n",
    "mlp_model = EmbeddingMLP(input_dim, hidden_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4fb9c0e-7503-4b9a-b3b6-bef4702c4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mlp_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07cb5d78-c1cc-4808-ba52-d606db94aa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.9406, Val Loss: 0.8163, Val Acc: 0.7762\n",
      "Epoch 2/50 - Train Loss: 0.7663, Val Loss: 0.6759, Val Acc: 0.7762\n",
      "Epoch 3/50 - Train Loss: 0.6526, Val Loss: 0.5752, Val Acc: 0.7762\n",
      "Epoch 4/50 - Train Loss: 0.5771, Val Loss: 0.5105, Val Acc: 0.8052\n",
      "Epoch 5/50 - Train Loss: 0.5277, Val Loss: 0.4741, Val Acc: 0.8169\n",
      "Epoch 6/50 - Train Loss: 0.4985, Val Loss: 0.4493, Val Acc: 0.8459\n",
      "Epoch 7/50 - Train Loss: 0.4772, Val Loss: 0.4360, Val Acc: 0.8459\n",
      "Epoch 8/50 - Train Loss: 0.4605, Val Loss: 0.4259, Val Acc: 0.8488\n",
      "Epoch 9/50 - Train Loss: 0.4489, Val Loss: 0.4206, Val Acc: 0.8459\n",
      "Epoch 10/50 - Train Loss: 0.4385, Val Loss: 0.4154, Val Acc: 0.8488\n",
      "Epoch 11/50 - Train Loss: 0.4300, Val Loss: 0.4151, Val Acc: 0.8459\n",
      "Epoch 12/50 - Train Loss: 0.4210, Val Loss: 0.4118, Val Acc: 0.8430\n",
      "Epoch 13/50 - Train Loss: 0.4166, Val Loss: 0.4097, Val Acc: 0.8488\n",
      "Epoch 14/50 - Train Loss: 0.4109, Val Loss: 0.4081, Val Acc: 0.8459\n",
      "Epoch 15/50 - Train Loss: 0.4096, Val Loss: 0.4077, Val Acc: 0.8459\n",
      "Epoch 16/50 - Train Loss: 0.4072, Val Loss: 0.4047, Val Acc: 0.8488\n",
      "Epoch 17/50 - Train Loss: 0.4042, Val Loss: 0.4057, Val Acc: 0.8459\n",
      "Epoch 18/50 - Train Loss: 0.4016, Val Loss: 0.4020, Val Acc: 0.8488\n",
      "Epoch 19/50 - Train Loss: 0.3994, Val Loss: 0.4020, Val Acc: 0.8488\n",
      "Epoch 20/50 - Train Loss: 0.3978, Val Loss: 0.3995, Val Acc: 0.8488\n",
      "Epoch 21/50 - Train Loss: 0.3983, Val Loss: 0.3995, Val Acc: 0.8488\n",
      "Epoch 22/50 - Train Loss: 0.4004, Val Loss: 0.3991, Val Acc: 0.8488\n",
      "Epoch 23/50 - Train Loss: 0.3930, Val Loss: 0.4010, Val Acc: 0.8459\n",
      "Epoch 24/50 - Train Loss: 0.3923, Val Loss: 0.3969, Val Acc: 0.8488\n",
      "Epoch 25/50 - Train Loss: 0.3909, Val Loss: 0.3970, Val Acc: 0.8488\n",
      "Epoch 26/50 - Train Loss: 0.3914, Val Loss: 0.3979, Val Acc: 0.8517\n",
      "Epoch 27/50 - Train Loss: 0.4037, Val Loss: 0.4164, Val Acc: 0.8488\n",
      "Epoch 28/50 - Train Loss: 0.3983, Val Loss: 0.4010, Val Acc: 0.8488\n",
      "Epoch 29/50 - Train Loss: 0.3916, Val Loss: 0.3961, Val Acc: 0.8517\n",
      "Epoch 30/50 - Train Loss: 0.3880, Val Loss: 0.3972, Val Acc: 0.8517\n",
      "Epoch 31/50 - Train Loss: 0.3873, Val Loss: 0.3962, Val Acc: 0.8517\n",
      "Epoch 32/50 - Train Loss: 0.3874, Val Loss: 0.3968, Val Acc: 0.8517\n",
      "Epoch 33/50 - Train Loss: 0.3867, Val Loss: 0.3965, Val Acc: 0.8517\n",
      "Epoch 34/50 - Train Loss: 0.3857, Val Loss: 0.3960, Val Acc: 0.8517\n",
      "Epoch 35/50 - Train Loss: 0.3902, Val Loss: 0.3952, Val Acc: 0.8517\n",
      "Epoch 36/50 - Train Loss: 0.3850, Val Loss: 0.3951, Val Acc: 0.8517\n",
      "Epoch 37/50 - Train Loss: 0.3877, Val Loss: 0.3938, Val Acc: 0.8517\n",
      "Epoch 38/50 - Train Loss: 0.3845, Val Loss: 0.3941, Val Acc: 0.8517\n",
      "Epoch 39/50 - Train Loss: 0.3834, Val Loss: 0.3946, Val Acc: 0.8517\n",
      "Epoch 40/50 - Train Loss: 0.3839, Val Loss: 0.3942, Val Acc: 0.8547\n",
      "Epoch 41/50 - Train Loss: 0.3877, Val Loss: 0.3958, Val Acc: 0.8517\n",
      "Epoch 42/50 - Train Loss: 0.3834, Val Loss: 0.3949, Val Acc: 0.8547\n",
      "Epoch 43/50 - Train Loss: 0.3824, Val Loss: 0.3944, Val Acc: 0.8517\n",
      "Epoch 44/50 - Train Loss: 0.3819, Val Loss: 0.3928, Val Acc: 0.8547\n",
      "Epoch 45/50 - Train Loss: 0.3822, Val Loss: 0.3941, Val Acc: 0.8517\n",
      "Epoch 46/50 - Train Loss: 0.3821, Val Loss: 0.3925, Val Acc: 0.8547\n",
      "Epoch 47/50 - Train Loss: 0.3810, Val Loss: 0.3928, Val Acc: 0.8547\n",
      "Epoch 48/50 - Train Loss: 0.3807, Val Loss: 0.3916, Val Acc: 0.8547\n",
      "Epoch 49/50 - Train Loss: 0.3817, Val Loss: 0.3930, Val Acc: 0.8547\n",
      "Epoch 50/50 - Train Loss: 0.3800, Val Loss: 0.3928, Val Acc: 0.8547\n"
     ]
    }
   ],
   "source": [
    "# Training loop with early stopping.\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    mlp_model.train()\n",
    "    running_loss = 0.0\n",
    "    for emb, labels in train_loader_mlp:\n",
    "        emb, labels = emb.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp_model(emb)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * emb.size(0)\n",
    "    train_loss = running_loss / len(train_loader_mlp.dataset)\n",
    "    \n",
    "    mlp_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for emb, labels in val_loader_mlp:\n",
    "            emb, labels = emb.to(device), labels.to(device)\n",
    "            outputs = mlp_model(emb)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * emb.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    val_loss = val_loss / len(val_loader_mlp.dataset)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(mlp_model.state_dict(), \"best_mlp_from_emb.pth\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26116348-c6ea-4c4b-b754-b2d3fada76ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test Accuracy: 0.8927536231884058\n",
      "MLP Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.89      0.67      0.76        72\n",
      "          CN       0.98      0.95      0.97       106\n",
      "         MCI       0.85      0.95      0.90       167\n",
      "\n",
      "    accuracy                           0.89       345\n",
      "   macro avg       0.91      0.86      0.87       345\n",
      "weighted avg       0.90      0.89      0.89       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best MLP model and evaluate on the test set.\n",
    "mlp_model.load_state_dict(torch.load(\"best_mlp_from_emb.pth\", map_location=device))\n",
    "mlp_model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for emb, labels in test_loader_mlp:\n",
    "        emb = emb.to(device)\n",
    "        outputs = mlp_model(emb)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "test_preds_mlp = np.concatenate(all_preds, axis=0)\n",
    "\n",
    "print(\"MLP Test Accuracy:\", accuracy_score(y_test, test_preds_mlp))\n",
    "print(\"MLP Classification Report (Test):\")\n",
    "print(classification_report(y_test, test_preds_mlp, target_names=[str(c) for c in label_encoder.classes_]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
