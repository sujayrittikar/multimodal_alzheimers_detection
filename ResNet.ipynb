{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3455993e-ed6a-4829-84e9-a62407d26ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rittikar-s/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/usr/lib/python3/dist-packages/skimage/morphology/_skeletonize.py:241: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  0, 1, 1, 0, 0, 1, 0, 0, 0], dtype=np.bool)\n",
      "/usr/lib/python3/dist-packages/skimage/morphology/_skeletonize.py:241: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  0, 1, 1, 0, 0, 1, 0, 0, 0], dtype=np.bool)\n",
      "/usr/lib/python3/dist-packages/skimage/morphology/_skeletonize.py:241: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  0, 1, 1, 0, 0, 1, 0, 0, 0], dtype=np.bool)\n",
      "/usr/lib/python3/dist-packages/skimage/morphology/_skeletonize.py:241: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  0, 1, 1, 0, 0, 1, 0, 0, 0], dtype=np.bool)\n",
      "/usr/lib/python3/dist-packages/skimage/morphology/_skeletonize.py:241: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  0, 1, 1, 0, 0, 1, 0, 0, 0], dtype=np.bool)\n",
      "/usr/lib/python3/dist-packages/skimage/morphology/_skeletonize.py:241: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  0, 1, 1, 0, 0, 1, 0, 0, 0], dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.ndimage\n",
    "from monai.networks.nets import resnet18\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82031009-3daa-4f23-8475-52bf27817815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nifti(nifti_path, target_shape=(128, 128, 128)):\n",
    "    # Normalize intensity to [0,1]\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
    "    # Resize to target shape: \n",
    "    img_resized = scipy.ndimage.zoom(img, np.array(target_shape) / np.array(img.shape), order=1)\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eee284f-c4a1-4ee2-8702-3e88442b07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_files_with_substring(directory, substring):\n",
    "    matching_files = [f for f in os.listdir(directory) if substring in f]\n",
    "    return matching_files\n",
    "\n",
    "def get_nib_image(adni_file_name):\n",
    "    return nib.load(adni_file_name).get_fdata()\n",
    "\n",
    "def visualize_image(nib_image):\n",
    "    plt.imshow(nib_image[:,:,nib_image.shape[2]//2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9a572e-b219-45f2-a56a-5c22ac465202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a simple function which returns the subject's image files in nib format based on subject id and optional date.\n",
    "# Use the dip_project/adni_subject_file_ma.json to search for the file(s) or, os paths.\n",
    "def get_image_file_names_for_subject(subject_id, date=None):\n",
    "    os.path.expanduser(\"~/adni_flat_dataset\")\n",
    "    dir_ = \"/home/rittikar-s/adni_flat_dataset\"\n",
    "    files = find_files_with_substring(dir_, subject_id)\n",
    "    if date:\n",
    "        files = [file for file in files if date in file]\n",
    "    file_paths = [f\"{dir_}/{file}\" for file in files]\n",
    "    return file_paths\n",
    "    # nib_images = []\n",
    "    # for file in files:\n",
    "    #     nib_image = get_nib_image(f\"{dir_}/{file}\")\n",
    "    #     nib_images.append(nib_image)\n",
    "    # return nib_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf43dd90-d257-480f-8d1b-11e152e97526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ADNI1_Complete_1Yr_1.5T_1_26_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e35e16-5ddd-42d9-ad7c-a1c293557a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, target_shape=(128, 128, 128)):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def preprocess_nifti(self, nifti_path):\n",
    "        img = nib.load(nifti_path).get_fdata()\n",
    "        \n",
    "        # Normalize intensity to [0,1]\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
    "        \n",
    "        # Resize to target shape\n",
    "        img_resized = scipy.ndimage.zoom(img, np.array(self.target_shape) / np.array(img.shape), order=1)\n",
    "        \n",
    "        return torch.tensor(img_resized, dtype=torch.float32).unsqueeze(0)  # Add channel dim\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.preprocess_nifti(self.image_paths[idx])\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977cb9e4-b95f-4ae5-a66d-2cbbe58c9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_label = {\n",
    "    \"CN\": 0,\n",
    "    \"MCI\": 1,\n",
    "    \"AD\": 2\n",
    "}\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    subject = row[\"Subject\"]\n",
    "    date = row[\"Acq Date\"]\n",
    "    date = date.replace(\"/\", \"-\")\n",
    "    image_path = get_image_file_names_for_subject(subject, date)[0]\n",
    "    image_paths.append(image_path)\n",
    "    labels.append(class_to_label[row[\"Group\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa87b64-5d7b-45dc-9aa1-96aa57f156fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5c0cdb-a93b-4c8d-b460-8a77ffd84bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a460a41c-8608-4a63-bc4a-7499afc3af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.3, random_state=42)\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(test_paths, test_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e16d48c-c208-49a2-8b8e-82298c052494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batches: 402, Val Batches: 86, Test Batches: 87\n"
     ]
    }
   ],
   "source": [
    "# Create train & test datasets\n",
    "train_dataset = NiftiDataset(train_paths, train_labels)\n",
    "val_dataset = NiftiDataset(val_paths, val_labels)\n",
    "test_dataset = NiftiDataset(test_paths, test_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "print(f\"Train Batches: {len(train_loader)}, Val Batches: {len(val_loader)}, Test Batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a2b9c7-12bd-4d0f-85a4-6f822ce4efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet-based classifier\n",
    "class ResNet3DClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet3DClassifier, self).__init__()\n",
    "        self.resnet = resnet18(spatial_dims=3, n_input_channels=1, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Instantiate model\n",
    "num_classes = 3\n",
    "model = ResNet3DClassifier(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ccef365-3184-48d5-bc89-cddf307b66ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet3DClassifier(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResNetBlock(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ResNetBlock(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResNetBlock(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetBlock(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResNetBlock(\n",
       "        (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetBlock(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): ResNetBlock(\n",
       "        (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetBlock(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Compute class weights\n",
    "classes = np.unique(train_labels)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=train_labels)\n",
    "\n",
    "# Define loss function & optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e5d3851-22a1-4b55-938e-55175989ce00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_550973/218538092.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 1/20:   0%|                                                                               | 0/402 [00:00<?, ?it/s]/tmp/ipykernel_550973/218538092.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/20: 100%|██████████████████████████████████████████| 402/402 [11:07<00:00,  1.66s/it, accuracy=44.9, loss=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      "  🔹 Train Loss: 1.0819, Train Accuracy: 44.86%\n",
      "  🔹 Val Loss: 1.1966, Val Accuracy: 47.97%\n",
      "✅ Best Model Saved! (Val Loss: 1.1966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████████████| 402/402 [11:13<00:00,  1.67s/it, accuracy=47.8, loss=0.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]\n",
      "  🔹 Train Loss: 1.0369, Train Accuracy: 47.79%\n",
      "  🔹 Val Loss: 0.9838, Val Accuracy: 48.26%\n",
      "✅ Best Model Saved! (Val Loss: 0.9838)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████████████████████████████████████| 402/402 [11:09<00:00,  1.67s/it, accuracy=48.5, loss=0.388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]\n",
      "  🔹 Train Loss: 1.0153, Train Accuracy: 48.47%\n",
      "  🔹 Val Loss: 1.0765, Val Accuracy: 48.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████████████████████████████████████| 402/402 [11:07<00:00,  1.66s/it, accuracy=50.2, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]\n",
      "  🔹 Train Loss: 0.9980, Train Accuracy: 50.16%\n",
      "  🔹 Val Loss: 1.0566, Val Accuracy: 48.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████████████████████████████████████| 402/402 [11:17<00:00,  1.69s/it, accuracy=53.3, loss=0.624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]\n",
      "  🔹 Train Loss: 0.9496, Train Accuracy: 53.27%\n",
      "  🔹 Val Loss: 0.9724, Val Accuracy: 44.48%\n",
      "✅ Best Model Saved! (Val Loss: 0.9724)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████████████████████████████| 402/402 [11:16<00:00,  1.68s/it, accuracy=54.2, loss=0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]\n",
      "  🔹 Train Loss: 0.9217, Train Accuracy: 54.21%\n",
      "  🔹 Val Loss: 0.9357, Val Accuracy: 51.16%\n",
      "✅ Best Model Saved! (Val Loss: 0.9357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████████████████████████████| 402/402 [11:12<00:00,  1.67s/it, accuracy=56.1, loss=0.293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]\n",
      "  🔹 Train Loss: 0.8969, Train Accuracy: 56.07%\n",
      "  🔹 Val Loss: 0.8972, Val Accuracy: 58.43%\n",
      "✅ Best Model Saved! (Val Loss: 0.8972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████████████████████████████| 402/402 [11:11<00:00,  1.67s/it, accuracy=58.9, loss=0.877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]\n",
      "  🔹 Train Loss: 0.8461, Train Accuracy: 58.88%\n",
      "  🔹 Val Loss: 0.8792, Val Accuracy: 56.98%\n",
      "✅ Best Model Saved! (Val Loss: 0.8792)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|███████████████████████████████████| 402/402 [10:47<00:00,  1.61s/it, accuracy=62.3, loss=0.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]\n",
      "  🔹 Train Loss: 0.8013, Train Accuracy: 62.31%\n",
      "  🔹 Val Loss: 1.2220, Val Accuracy: 51.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|█████████████████████████████████| 402/402 [11:03<00:00,  1.65s/it, accuracy=63.1, loss=0.477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]\n",
      "  🔹 Train Loss: 0.7705, Train Accuracy: 63.12%\n",
      "  🔹 Val Loss: 1.2360, Val Accuracy: 39.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|███████████████████████████████████| 402/402 [11:01<00:00,  1.64s/it, accuracy=69, loss=0.651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]\n",
      "  🔹 Train Loss: 0.6949, Train Accuracy: 68.97%\n",
      "  🔹 Val Loss: 0.7726, Val Accuracy: 65.99%\n",
      "✅ Best Model Saved! (Val Loss: 0.7726)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|█████████████████████████████████| 402/402 [11:16<00:00,  1.68s/it, accuracy=73.3, loss=0.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]\n",
      "  🔹 Train Loss: 0.6075, Train Accuracy: 73.27%\n",
      "  🔹 Val Loss: 0.9886, Val Accuracy: 59.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|█████████████████████████████████| 402/402 [11:16<00:00,  1.68s/it, accuracy=78.4, loss=0.238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]\n",
      "  🔹 Train Loss: 0.5621, Train Accuracy: 78.38%\n",
      "  🔹 Val Loss: 0.9848, Val Accuracy: 59.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|█████████████████████████████████| 402/402 [10:50<00:00,  1.62s/it, accuracy=83.9, loss=0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]\n",
      "  🔹 Train Loss: 0.4272, Train Accuracy: 83.86%\n",
      "  🔹 Val Loss: 1.0863, Val Accuracy: 55.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|█████████████████████████████████| 402/402 [10:49<00:00,  1.62s/it, accuracy=91.7, loss=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]\n",
      "  🔹 Train Loss: 0.2383, Train Accuracy: 91.71%\n",
      "  🔹 Val Loss: 0.9555, Val Accuracy: 70.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|█████████████████████████████████| 402/402 [11:01<00:00,  1.65s/it, accuracy=94.8, loss=0.487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20]\n",
      "  🔹 Train Loss: 0.1768, Train Accuracy: 94.83%\n",
      "  🔹 Val Loss: 0.8264, Val Accuracy: 72.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|█████████████████████████████████| 402/402 [10:53<00:00,  1.62s/it, accuracy=95.8, loss=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20]\n",
      "  🔹 Train Loss: 0.1459, Train Accuracy: 95.83%\n",
      "  🔹 Val Loss: 0.7889, Val Accuracy: 71.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|█████████████████████████████████| 402/402 [10:45<00:00,  1.61s/it, accuracy=97.1, loss=0.853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20]\n",
      "  🔹 Train Loss: 0.1182, Train Accuracy: 97.07%\n",
      "  🔹 Val Loss: 0.7538, Val Accuracy: 74.42%\n",
      "✅ Best Model Saved! (Val Loss: 0.7538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|████████████████████████████████| 402/402 [11:08<00:00,  1.66s/it, accuracy=99.3, loss=0.0522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20]\n",
      "  🔹 Train Loss: 0.0674, Train Accuracy: 99.25%\n",
      "  🔹 Val Loss: 0.7326, Val Accuracy: 74.13%\n",
      "✅ Best Model Saved! (Val Loss: 0.7326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|████████████████████████████████| 402/402 [11:01<00:00,  1.65s/it, accuracy=98.9, loss=0.0409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20]\n",
      "  🔹 Train Loss: 0.0642, Train Accuracy: 98.94%\n",
      "  🔹 Val Loss: 0.8186, Val Accuracy: 73.55%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from tqdm import tqdm  # Progress bar\n",
    "import os\n",
    "\n",
    "# Ensure model directory exists\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, accumulation_steps=2, device=\"cuda\"):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = \"models/best_model.pth\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        # Use tqdm for progress bar\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for i, (images, labels) in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels) / accumulation_steps  # Divide loss for accumulation\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * accumulation_steps  # Undo division for correct loss tracking\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix(loss=loss.item(), accuracy=100 * correct / total)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # **Validation Phase**\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        # Adjust LR based on **validation loss**\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"  🔹 Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"  🔹 Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"✅ Best Model Saved! (Val Loss: {best_val_loss:.4f})\")\n",
    "\n",
    "# Train the model with validation and best model saving\n",
    "train_model(model, train_loader, val_loader, num_epochs=20, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e35949cc-e358-4fcf-9cc5-ef1f1ee8f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7864    0.8182    0.8020        99\n",
      "           1     0.7500    0.8521    0.7978       169\n",
      "           2     0.8400    0.5455    0.6614        77\n",
      "\n",
      "    accuracy                         0.7739       345\n",
      "   macro avg     0.7921    0.7386    0.7537       345\n",
      "weighted avg     0.7805    0.7739    0.7686       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(all_labels, all_preds, digits=4)\n",
    "    print(\"\\n🔹 Classification Report:\\n\")\n",
    "    print(report)\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
