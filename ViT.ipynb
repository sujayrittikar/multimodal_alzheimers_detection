{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51807170-1d84-4c68-b8ff-6827b6599159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.ndimage\n",
    "from monai.networks.nets import resnet18\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fcc886-2bed-428c-b812-0950f5390e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nifti(nifti_path, target_shape=(128, 128, 128)):\n",
    "    # Normalize intensity to [0,1]\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
    "    # Resize to target shape: \n",
    "    img_resized = scipy.ndimage.zoom(img, np.array(target_shape) / np.array(img.shape), order=1)\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e579606-2ae8-43dd-95f9-9f9f25530b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_files_with_substring(directory, substring):\n",
    "    matching_files = [f for f in os.listdir(directory) if substring in f]\n",
    "    return matching_files\n",
    "\n",
    "def get_nib_image(adni_file_name):\n",
    "    return nib.load(adni_file_name).get_fdata()\n",
    "\n",
    "def visualize_image(nib_image):\n",
    "    plt.imshow(nib_image[:,:,nib_image.shape[2]//2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f021e5-6aab-4e1c-89d1-6453028f7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_file_names_for_subject(subject_id, date=None):\n",
    "    os.path.expanduser(\"~/adni_flat_dataset/adni_flat_dataset\")\n",
    "    dir_ = \"/home/rittikar-s/adni_flat_dataset/adni_flat_dataset\"\n",
    "    files = find_files_with_substring(dir_, subject_id)\n",
    "    if date:\n",
    "        files = [file for file in files if date in file]\n",
    "    file_paths = [f\"{dir_}/{file}\" for file in files]\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01308a7-4fa8-4e4a-b42a-ccb401de8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ADNI1_Complete_1Yr_1.5T_1_26_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4be2a0-6cf7-422c-bb27-23a77776d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets.vitautoenc import ViTAutoEnc\n",
    "\n",
    "vit_model = ViTAutoEnc(in_channels=1, patch_size=(16,16,16), img_size=(128,128,128))\n",
    "\n",
    "def get_vit_embedding(img):\n",
    "    return vit_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9723c9f4-ec96-41be-b7c8-9f24de00ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, target_shape=(128, 128, 128)):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def preprocess_nifti(self, nifti_path):\n",
    "        img = nib.load(nifti_path).get_fdata()\n",
    "        \n",
    "        # Normalize intensity to [0,1]\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
    "        \n",
    "        # Resize to target shape\n",
    "        img_resized = scipy.ndimage.zoom(img, np.array(self.target_shape) / np.array(img.shape), order=1)\n",
    "        \n",
    "        return torch.tensor(img_resized, dtype=torch.float32).unsqueeze(0)  # Add channel dim\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.preprocess_nifti(self.image_paths[idx])\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        embedding = get_vit_embedding(image.reshape(1,1,128,128,128))\n",
    "        return embedding, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62036a9f-e976-4fd0-aef5-4ea71b88072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_label = {\n",
    "    \"CN\": 0,\n",
    "    \"MCI\": 1,\n",
    "    \"AD\": 2\n",
    "}\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    subject = row[\"Subject\"]\n",
    "    date = row[\"Acq Date\"]\n",
    "    date = date.replace(\"/\", \"-\")\n",
    "    image_path = get_image_file_names_for_subject(subject, date)[0]\n",
    "    image_paths.append(image_path)\n",
    "    labels.append(class_to_label[row[\"Group\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc86ce3e-ef67-4492-b81e-4174b4f8084f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5306e8-85f3-4a47-9e2d-048b87bdb7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff88cf5-1448-4d1f-aa93-964640bfa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(test_paths, test_labels, test_size=0.5, random_state=42, stratify=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6107f004-c758-45c2-a4c9-6c352027cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batches: 402, Val Batches: 86, Test Batches: 87\n"
     ]
    }
   ],
   "source": [
    "# Create train & test datasets\n",
    "train_dataset = NiftiDataset(train_paths, train_labels)\n",
    "val_dataset = NiftiDataset(val_paths, val_labels)\n",
    "test_dataset = NiftiDataset(test_paths, test_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "print(f\"Train Batches: {len(train_loader)}, Val Batches: {len(val_loader)}, Test Batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "175d94f2-5922-4e14-9b95-f428d1555e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_embeddings_hdf5(dataloader, filename):\n",
    "    \"\"\"Save embeddings (from list format) and labels incrementally to an HDF5 file.\"\"\"\n",
    "    with h5py.File(filename, \"w\") as f:\n",
    "        first_batch = True\n",
    "        for i, (embedding_list, label) in enumerate(dataloader):\n",
    "            # Extract the last layer embeddings\n",
    "            embedding_tensor = embedding_list[1][-1]  # Extract final layer embeddings\n",
    "            embedding_tensor = embedding_tensor.cpu().detach()  # Move to CPU\n",
    "            \n",
    "            embedding_numpy = embedding_tensor.numpy()  # Convert to NumPy\n",
    "            label_numpy = label.cpu().numpy()\n",
    "\n",
    "            # Reshape embeddings if needed\n",
    "            embedding_numpy = embedding_numpy.reshape(embedding_numpy.shape[0], -1)  # (4, 1, 512, 768) → (4, 512 * 768)\n",
    "\n",
    "            if first_batch:\n",
    "                # Create expandable datasets with correct shape\n",
    "                f.create_dataset(\"embeddings\", data=embedding_numpy, \n",
    "                                 maxshape=(None, embedding_numpy.shape[1]))  # Now 2D\n",
    "                f.create_dataset(\"labels\", data=label_numpy, maxshape=(None,))\n",
    "                first_batch = False\n",
    "            else:\n",
    "                # Resize and append new embeddings\n",
    "                f[\"embeddings\"].resize((f[\"embeddings\"].shape[0] + embedding_numpy.shape[0]), axis=0)\n",
    "                f[\"embeddings\"][-embedding_numpy.shape[0]:] = embedding_numpy\n",
    "\n",
    "                f[\"labels\"].resize((f[\"labels\"].shape[0] + label_numpy.shape[0]), axis=0)\n",
    "                f[\"labels\"][-label_numpy.shape[0]:] = label_numpy\n",
    "            \n",
    "            print(f\"Saved embeddings for batch: {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a120898e-b143-40a4-a31f-3fabcb857139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings for batch: 1\n",
      "Saved embeddings for batch: 2\n",
      "Saved embeddings for batch: 3\n",
      "Saved embeddings for batch: 4\n",
      "Saved embeddings for batch: 5\n",
      "Saved embeddings for batch: 6\n",
      "Saved embeddings for batch: 7\n",
      "Saved embeddings for batch: 8\n",
      "Saved embeddings for batch: 9\n",
      "Saved embeddings for batch: 10\n",
      "Saved embeddings for batch: 11\n",
      "Saved embeddings for batch: 12\n",
      "Saved embeddings for batch: 13\n",
      "Saved embeddings for batch: 14\n",
      "Saved embeddings for batch: 15\n",
      "Saved embeddings for batch: 16\n",
      "Saved embeddings for batch: 17\n",
      "Saved embeddings for batch: 18\n",
      "Saved embeddings for batch: 19\n",
      "Saved embeddings for batch: 20\n",
      "Saved embeddings for batch: 21\n",
      "Saved embeddings for batch: 22\n",
      "Saved embeddings for batch: 23\n",
      "Saved embeddings for batch: 24\n",
      "Saved embeddings for batch: 25\n",
      "Saved embeddings for batch: 26\n",
      "Saved embeddings for batch: 27\n",
      "Saved embeddings for batch: 28\n",
      "Saved embeddings for batch: 29\n",
      "Saved embeddings for batch: 30\n",
      "Saved embeddings for batch: 31\n",
      "Saved embeddings for batch: 32\n",
      "Saved embeddings for batch: 33\n",
      "Saved embeddings for batch: 34\n",
      "Saved embeddings for batch: 35\n",
      "Saved embeddings for batch: 36\n",
      "Saved embeddings for batch: 37\n",
      "Saved embeddings for batch: 38\n",
      "Saved embeddings for batch: 39\n",
      "Saved embeddings for batch: 40\n",
      "Saved embeddings for batch: 41\n",
      "Saved embeddings for batch: 42\n",
      "Saved embeddings for batch: 43\n",
      "Saved embeddings for batch: 44\n",
      "Saved embeddings for batch: 45\n",
      "Saved embeddings for batch: 46\n",
      "Saved embeddings for batch: 47\n",
      "Saved embeddings for batch: 48\n",
      "Saved embeddings for batch: 49\n",
      "Saved embeddings for batch: 50\n",
      "Saved embeddings for batch: 51\n",
      "Saved embeddings for batch: 52\n",
      "Saved embeddings for batch: 53\n",
      "Saved embeddings for batch: 54\n",
      "Saved embeddings for batch: 55\n",
      "Saved embeddings for batch: 56\n",
      "Saved embeddings for batch: 57\n",
      "Saved embeddings for batch: 58\n",
      "Saved embeddings for batch: 59\n",
      "Saved embeddings for batch: 60\n",
      "Saved embeddings for batch: 61\n",
      "Saved embeddings for batch: 62\n",
      "Saved embeddings for batch: 63\n",
      "Saved embeddings for batch: 64\n",
      "Saved embeddings for batch: 65\n",
      "Saved embeddings for batch: 66\n",
      "Saved embeddings for batch: 67\n",
      "Saved embeddings for batch: 68\n",
      "Saved embeddings for batch: 69\n",
      "Saved embeddings for batch: 70\n",
      "Saved embeddings for batch: 71\n",
      "Saved embeddings for batch: 72\n",
      "Saved embeddings for batch: 73\n",
      "Saved embeddings for batch: 74\n",
      "Saved embeddings for batch: 75\n",
      "Saved embeddings for batch: 76\n",
      "Saved embeddings for batch: 77\n",
      "Saved embeddings for batch: 78\n",
      "Saved embeddings for batch: 79\n",
      "Saved embeddings for batch: 80\n",
      "Saved embeddings for batch: 81\n",
      "Saved embeddings for batch: 82\n",
      "Saved embeddings for batch: 83\n",
      "Saved embeddings for batch: 84\n",
      "Saved embeddings for batch: 85\n",
      "Saved embeddings for batch: 86\n",
      "Saved embeddings for batch: 87\n",
      "Saved embeddings for batch: 88\n",
      "Saved embeddings for batch: 89\n",
      "Saved embeddings for batch: 90\n",
      "Saved embeddings for batch: 91\n",
      "Saved embeddings for batch: 92\n",
      "Saved embeddings for batch: 93\n",
      "Saved embeddings for batch: 94\n",
      "Saved embeddings for batch: 95\n",
      "Saved embeddings for batch: 96\n",
      "Saved embeddings for batch: 97\n",
      "Saved embeddings for batch: 98\n",
      "Saved embeddings for batch: 99\n",
      "Saved embeddings for batch: 100\n",
      "Saved embeddings for batch: 101\n",
      "Saved embeddings for batch: 102\n",
      "Saved embeddings for batch: 103\n",
      "Saved embeddings for batch: 104\n",
      "Saved embeddings for batch: 105\n",
      "Saved embeddings for batch: 106\n",
      "Saved embeddings for batch: 107\n",
      "Saved embeddings for batch: 108\n",
      "Saved embeddings for batch: 109\n",
      "Saved embeddings for batch: 110\n",
      "Saved embeddings for batch: 111\n",
      "Saved embeddings for batch: 112\n",
      "Saved embeddings for batch: 113\n",
      "Saved embeddings for batch: 114\n",
      "Saved embeddings for batch: 115\n",
      "Saved embeddings for batch: 116\n",
      "Saved embeddings for batch: 117\n",
      "Saved embeddings for batch: 118\n",
      "Saved embeddings for batch: 119\n",
      "Saved embeddings for batch: 120\n",
      "Saved embeddings for batch: 121\n",
      "Saved embeddings for batch: 122\n",
      "Saved embeddings for batch: 123\n",
      "Saved embeddings for batch: 124\n",
      "Saved embeddings for batch: 125\n",
      "Saved embeddings for batch: 126\n",
      "Saved embeddings for batch: 127\n",
      "Saved embeddings for batch: 128\n",
      "Saved embeddings for batch: 129\n",
      "Saved embeddings for batch: 130\n",
      "Saved embeddings for batch: 131\n",
      "Saved embeddings for batch: 132\n",
      "Saved embeddings for batch: 133\n",
      "Saved embeddings for batch: 134\n",
      "Saved embeddings for batch: 135\n",
      "Saved embeddings for batch: 136\n",
      "Saved embeddings for batch: 137\n",
      "Saved embeddings for batch: 138\n",
      "Saved embeddings for batch: 139\n",
      "Saved embeddings for batch: 140\n",
      "Saved embeddings for batch: 141\n",
      "Saved embeddings for batch: 142\n",
      "Saved embeddings for batch: 143\n",
      "Saved embeddings for batch: 144\n",
      "Saved embeddings for batch: 145\n",
      "Saved embeddings for batch: 146\n",
      "Saved embeddings for batch: 147\n",
      "Saved embeddings for batch: 148\n",
      "Saved embeddings for batch: 149\n",
      "Saved embeddings for batch: 150\n",
      "Saved embeddings for batch: 151\n",
      "Saved embeddings for batch: 152\n",
      "Saved embeddings for batch: 153\n",
      "Saved embeddings for batch: 154\n",
      "Saved embeddings for batch: 155\n",
      "Saved embeddings for batch: 156\n",
      "Saved embeddings for batch: 157\n",
      "Saved embeddings for batch: 158\n",
      "Saved embeddings for batch: 159\n",
      "Saved embeddings for batch: 160\n",
      "Saved embeddings for batch: 161\n",
      "Saved embeddings for batch: 162\n",
      "Saved embeddings for batch: 163\n",
      "Saved embeddings for batch: 164\n",
      "Saved embeddings for batch: 165\n",
      "Saved embeddings for batch: 166\n",
      "Saved embeddings for batch: 167\n",
      "Saved embeddings for batch: 168\n",
      "Saved embeddings for batch: 169\n",
      "Saved embeddings for batch: 170\n",
      "Saved embeddings for batch: 171\n",
      "Saved embeddings for batch: 172\n",
      "Saved embeddings for batch: 173\n",
      "Saved embeddings for batch: 174\n",
      "Saved embeddings for batch: 175\n",
      "Saved embeddings for batch: 176\n",
      "Saved embeddings for batch: 177\n",
      "Saved embeddings for batch: 178\n",
      "Saved embeddings for batch: 179\n",
      "Saved embeddings for batch: 180\n",
      "Saved embeddings for batch: 181\n",
      "Saved embeddings for batch: 182\n",
      "Saved embeddings for batch: 183\n",
      "Saved embeddings for batch: 184\n",
      "Saved embeddings for batch: 185\n",
      "Saved embeddings for batch: 186\n",
      "Saved embeddings for batch: 187\n",
      "Saved embeddings for batch: 188\n",
      "Saved embeddings for batch: 189\n",
      "Saved embeddings for batch: 190\n",
      "Saved embeddings for batch: 191\n",
      "Saved embeddings for batch: 192\n",
      "Saved embeddings for batch: 193\n",
      "Saved embeddings for batch: 194\n",
      "Saved embeddings for batch: 195\n",
      "Saved embeddings for batch: 196\n",
      "Saved embeddings for batch: 197\n",
      "Saved embeddings for batch: 198\n",
      "Saved embeddings for batch: 199\n",
      "Saved embeddings for batch: 200\n",
      "Saved embeddings for batch: 201\n",
      "Saved embeddings for batch: 202\n",
      "Saved embeddings for batch: 203\n",
      "Saved embeddings for batch: 204\n",
      "Saved embeddings for batch: 205\n",
      "Saved embeddings for batch: 206\n",
      "Saved embeddings for batch: 207\n",
      "Saved embeddings for batch: 208\n",
      "Saved embeddings for batch: 209\n",
      "Saved embeddings for batch: 210\n",
      "Saved embeddings for batch: 211\n",
      "Saved embeddings for batch: 212\n",
      "Saved embeddings for batch: 213\n",
      "Saved embeddings for batch: 214\n",
      "Saved embeddings for batch: 215\n",
      "Saved embeddings for batch: 216\n",
      "Saved embeddings for batch: 217\n",
      "Saved embeddings for batch: 218\n",
      "Saved embeddings for batch: 219\n",
      "Saved embeddings for batch: 220\n",
      "Saved embeddings for batch: 221\n",
      "Saved embeddings for batch: 222\n",
      "Saved embeddings for batch: 223\n",
      "Saved embeddings for batch: 224\n",
      "Saved embeddings for batch: 225\n",
      "Saved embeddings for batch: 226\n",
      "Saved embeddings for batch: 227\n",
      "Saved embeddings for batch: 228\n",
      "Saved embeddings for batch: 229\n",
      "Saved embeddings for batch: 230\n",
      "Saved embeddings for batch: 231\n",
      "Saved embeddings for batch: 232\n",
      "Saved embeddings for batch: 233\n",
      "Saved embeddings for batch: 234\n",
      "Saved embeddings for batch: 235\n",
      "Saved embeddings for batch: 236\n",
      "Saved embeddings for batch: 237\n",
      "Saved embeddings for batch: 238\n",
      "Saved embeddings for batch: 239\n",
      "Saved embeddings for batch: 240\n",
      "Saved embeddings for batch: 241\n",
      "Saved embeddings for batch: 242\n",
      "Saved embeddings for batch: 243\n",
      "Saved embeddings for batch: 244\n",
      "Saved embeddings for batch: 245\n",
      "Saved embeddings for batch: 246\n",
      "Saved embeddings for batch: 247\n",
      "Saved embeddings for batch: 248\n",
      "Saved embeddings for batch: 249\n",
      "Saved embeddings for batch: 250\n",
      "Saved embeddings for batch: 251\n",
      "Saved embeddings for batch: 252\n",
      "Saved embeddings for batch: 253\n",
      "Saved embeddings for batch: 254\n",
      "Saved embeddings for batch: 255\n",
      "Saved embeddings for batch: 256\n",
      "Saved embeddings for batch: 257\n",
      "Saved embeddings for batch: 258\n",
      "Saved embeddings for batch: 259\n",
      "Saved embeddings for batch: 260\n",
      "Saved embeddings for batch: 261\n",
      "Saved embeddings for batch: 262\n",
      "Saved embeddings for batch: 263\n",
      "Saved embeddings for batch: 264\n",
      "Saved embeddings for batch: 265\n",
      "Saved embeddings for batch: 266\n",
      "Saved embeddings for batch: 267\n",
      "Saved embeddings for batch: 268\n",
      "Saved embeddings for batch: 269\n",
      "Saved embeddings for batch: 270\n",
      "Saved embeddings for batch: 271\n",
      "Saved embeddings for batch: 272\n",
      "Saved embeddings for batch: 273\n",
      "Saved embeddings for batch: 274\n",
      "Saved embeddings for batch: 275\n",
      "Saved embeddings for batch: 276\n",
      "Saved embeddings for batch: 277\n",
      "Saved embeddings for batch: 278\n",
      "Saved embeddings for batch: 279\n",
      "Saved embeddings for batch: 280\n",
      "Saved embeddings for batch: 281\n",
      "Saved embeddings for batch: 282\n",
      "Saved embeddings for batch: 283\n",
      "Saved embeddings for batch: 284\n",
      "Saved embeddings for batch: 285\n",
      "Saved embeddings for batch: 286\n",
      "Saved embeddings for batch: 287\n",
      "Saved embeddings for batch: 288\n",
      "Saved embeddings for batch: 289\n",
      "Saved embeddings for batch: 290\n",
      "Saved embeddings for batch: 291\n",
      "Saved embeddings for batch: 292\n",
      "Saved embeddings for batch: 293\n",
      "Saved embeddings for batch: 294\n",
      "Saved embeddings for batch: 295\n",
      "Saved embeddings for batch: 296\n",
      "Saved embeddings for batch: 297\n",
      "Saved embeddings for batch: 298\n",
      "Saved embeddings for batch: 299\n",
      "Saved embeddings for batch: 300\n",
      "Saved embeddings for batch: 301\n",
      "Saved embeddings for batch: 302\n",
      "Saved embeddings for batch: 303\n",
      "Saved embeddings for batch: 304\n",
      "Saved embeddings for batch: 305\n",
      "Saved embeddings for batch: 306\n",
      "Saved embeddings for batch: 307\n",
      "Saved embeddings for batch: 308\n",
      "Saved embeddings for batch: 309\n",
      "Saved embeddings for batch: 310\n",
      "Saved embeddings for batch: 311\n",
      "Saved embeddings for batch: 312\n",
      "Saved embeddings for batch: 313\n",
      "Saved embeddings for batch: 314\n",
      "Saved embeddings for batch: 315\n",
      "Saved embeddings for batch: 316\n",
      "Saved embeddings for batch: 317\n",
      "Saved embeddings for batch: 318\n",
      "Saved embeddings for batch: 319\n",
      "Saved embeddings for batch: 320\n",
      "Saved embeddings for batch: 321\n",
      "Saved embeddings for batch: 322\n",
      "Saved embeddings for batch: 323\n",
      "Saved embeddings for batch: 324\n",
      "Saved embeddings for batch: 325\n",
      "Saved embeddings for batch: 326\n",
      "Saved embeddings for batch: 327\n",
      "Saved embeddings for batch: 328\n",
      "Saved embeddings for batch: 329\n",
      "Saved embeddings for batch: 330\n",
      "Saved embeddings for batch: 331\n",
      "Saved embeddings for batch: 332\n",
      "Saved embeddings for batch: 333\n",
      "Saved embeddings for batch: 334\n",
      "Saved embeddings for batch: 335\n",
      "Saved embeddings for batch: 336\n",
      "Saved embeddings for batch: 337\n",
      "Saved embeddings for batch: 338\n",
      "Saved embeddings for batch: 339\n",
      "Saved embeddings for batch: 340\n",
      "Saved embeddings for batch: 341\n",
      "Saved embeddings for batch: 342\n",
      "Saved embeddings for batch: 343\n",
      "Saved embeddings for batch: 344\n",
      "Saved embeddings for batch: 345\n",
      "Saved embeddings for batch: 346\n",
      "Saved embeddings for batch: 347\n",
      "Saved embeddings for batch: 348\n",
      "Saved embeddings for batch: 349\n",
      "Saved embeddings for batch: 350\n",
      "Saved embeddings for batch: 351\n",
      "Saved embeddings for batch: 352\n",
      "Saved embeddings for batch: 353\n",
      "Saved embeddings for batch: 354\n",
      "Saved embeddings for batch: 355\n",
      "Saved embeddings for batch: 356\n",
      "Saved embeddings for batch: 357\n",
      "Saved embeddings for batch: 358\n",
      "Saved embeddings for batch: 359\n",
      "Saved embeddings for batch: 360\n",
      "Saved embeddings for batch: 361\n",
      "Saved embeddings for batch: 362\n",
      "Saved embeddings for batch: 363\n",
      "Saved embeddings for batch: 364\n",
      "Saved embeddings for batch: 365\n",
      "Saved embeddings for batch: 366\n",
      "Saved embeddings for batch: 367\n",
      "Saved embeddings for batch: 368\n",
      "Saved embeddings for batch: 369\n",
      "Saved embeddings for batch: 370\n",
      "Saved embeddings for batch: 371\n",
      "Saved embeddings for batch: 372\n",
      "Saved embeddings for batch: 373\n",
      "Saved embeddings for batch: 374\n",
      "Saved embeddings for batch: 375\n",
      "Saved embeddings for batch: 376\n",
      "Saved embeddings for batch: 377\n",
      "Saved embeddings for batch: 378\n",
      "Saved embeddings for batch: 379\n",
      "Saved embeddings for batch: 380\n",
      "Saved embeddings for batch: 381\n",
      "Saved embeddings for batch: 382\n",
      "Saved embeddings for batch: 383\n",
      "Saved embeddings for batch: 384\n",
      "Saved embeddings for batch: 385\n",
      "Saved embeddings for batch: 386\n",
      "Saved embeddings for batch: 387\n",
      "Saved embeddings for batch: 388\n",
      "Saved embeddings for batch: 389\n",
      "Saved embeddings for batch: 390\n",
      "Saved embeddings for batch: 391\n",
      "Saved embeddings for batch: 392\n",
      "Saved embeddings for batch: 393\n",
      "Saved embeddings for batch: 394\n",
      "Saved embeddings for batch: 395\n",
      "Saved embeddings for batch: 396\n",
      "Saved embeddings for batch: 397\n",
      "Saved embeddings for batch: 398\n",
      "Saved embeddings for batch: 399\n",
      "Saved embeddings for batch: 400\n",
      "Saved embeddings for batch: 401\n",
      "Saved embeddings for batch: 402\n",
      "Saved embeddings for batch: 1\n",
      "Saved embeddings for batch: 2\n",
      "Saved embeddings for batch: 3\n",
      "Saved embeddings for batch: 4\n",
      "Saved embeddings for batch: 5\n",
      "Saved embeddings for batch: 6\n",
      "Saved embeddings for batch: 7\n",
      "Saved embeddings for batch: 8\n",
      "Saved embeddings for batch: 9\n",
      "Saved embeddings for batch: 10\n",
      "Saved embeddings for batch: 11\n",
      "Saved embeddings for batch: 12\n",
      "Saved embeddings for batch: 13\n",
      "Saved embeddings for batch: 14\n",
      "Saved embeddings for batch: 15\n",
      "Saved embeddings for batch: 16\n",
      "Saved embeddings for batch: 17\n",
      "Saved embeddings for batch: 18\n",
      "Saved embeddings for batch: 19\n",
      "Saved embeddings for batch: 20\n",
      "Saved embeddings for batch: 21\n",
      "Saved embeddings for batch: 22\n",
      "Saved embeddings for batch: 23\n",
      "Saved embeddings for batch: 24\n",
      "Saved embeddings for batch: 25\n",
      "Saved embeddings for batch: 26\n",
      "Saved embeddings for batch: 27\n",
      "Saved embeddings for batch: 28\n",
      "Saved embeddings for batch: 29\n",
      "Saved embeddings for batch: 30\n",
      "Saved embeddings for batch: 31\n",
      "Saved embeddings for batch: 32\n",
      "Saved embeddings for batch: 33\n",
      "Saved embeddings for batch: 34\n",
      "Saved embeddings for batch: 35\n",
      "Saved embeddings for batch: 36\n",
      "Saved embeddings for batch: 37\n",
      "Saved embeddings for batch: 38\n",
      "Saved embeddings for batch: 39\n",
      "Saved embeddings for batch: 40\n",
      "Saved embeddings for batch: 41\n",
      "Saved embeddings for batch: 42\n",
      "Saved embeddings for batch: 43\n",
      "Saved embeddings for batch: 44\n",
      "Saved embeddings for batch: 45\n",
      "Saved embeddings for batch: 46\n",
      "Saved embeddings for batch: 47\n",
      "Saved embeddings for batch: 48\n",
      "Saved embeddings for batch: 49\n",
      "Saved embeddings for batch: 50\n",
      "Saved embeddings for batch: 51\n",
      "Saved embeddings for batch: 52\n",
      "Saved embeddings for batch: 53\n",
      "Saved embeddings for batch: 54\n",
      "Saved embeddings for batch: 55\n",
      "Saved embeddings for batch: 56\n",
      "Saved embeddings for batch: 57\n",
      "Saved embeddings for batch: 58\n",
      "Saved embeddings for batch: 59\n",
      "Saved embeddings for batch: 60\n",
      "Saved embeddings for batch: 61\n",
      "Saved embeddings for batch: 62\n",
      "Saved embeddings for batch: 63\n",
      "Saved embeddings for batch: 64\n",
      "Saved embeddings for batch: 65\n",
      "Saved embeddings for batch: 66\n",
      "Saved embeddings for batch: 67\n",
      "Saved embeddings for batch: 68\n",
      "Saved embeddings for batch: 69\n",
      "Saved embeddings for batch: 70\n",
      "Saved embeddings for batch: 71\n",
      "Saved embeddings for batch: 72\n",
      "Saved embeddings for batch: 73\n",
      "Saved embeddings for batch: 74\n",
      "Saved embeddings for batch: 75\n",
      "Saved embeddings for batch: 76\n",
      "Saved embeddings for batch: 77\n",
      "Saved embeddings for batch: 78\n",
      "Saved embeddings for batch: 79\n",
      "Saved embeddings for batch: 80\n",
      "Saved embeddings for batch: 81\n",
      "Saved embeddings for batch: 82\n",
      "Saved embeddings for batch: 83\n",
      "Saved embeddings for batch: 84\n",
      "Saved embeddings for batch: 85\n",
      "Saved embeddings for batch: 86\n",
      "Saved embeddings for batch: 1\n",
      "Saved embeddings for batch: 2\n",
      "Saved embeddings for batch: 3\n",
      "Saved embeddings for batch: 4\n",
      "Saved embeddings for batch: 5\n",
      "Saved embeddings for batch: 6\n",
      "Saved embeddings for batch: 7\n",
      "Saved embeddings for batch: 8\n",
      "Saved embeddings for batch: 9\n",
      "Saved embeddings for batch: 10\n",
      "Saved embeddings for batch: 11\n",
      "Saved embeddings for batch: 12\n",
      "Saved embeddings for batch: 13\n",
      "Saved embeddings for batch: 14\n",
      "Saved embeddings for batch: 15\n",
      "Saved embeddings for batch: 16\n",
      "Saved embeddings for batch: 17\n",
      "Saved embeddings for batch: 18\n",
      "Saved embeddings for batch: 19\n",
      "Saved embeddings for batch: 20\n",
      "Saved embeddings for batch: 21\n",
      "Saved embeddings for batch: 22\n",
      "Saved embeddings for batch: 23\n",
      "Saved embeddings for batch: 24\n",
      "Saved embeddings for batch: 25\n",
      "Saved embeddings for batch: 26\n",
      "Saved embeddings for batch: 27\n",
      "Saved embeddings for batch: 28\n",
      "Saved embeddings for batch: 29\n",
      "Saved embeddings for batch: 30\n",
      "Saved embeddings for batch: 31\n",
      "Saved embeddings for batch: 32\n",
      "Saved embeddings for batch: 33\n",
      "Saved embeddings for batch: 34\n",
      "Saved embeddings for batch: 35\n",
      "Saved embeddings for batch: 36\n",
      "Saved embeddings for batch: 37\n",
      "Saved embeddings for batch: 38\n",
      "Saved embeddings for batch: 39\n",
      "Saved embeddings for batch: 40\n",
      "Saved embeddings for batch: 41\n",
      "Saved embeddings for batch: 42\n",
      "Saved embeddings for batch: 43\n",
      "Saved embeddings for batch: 44\n",
      "Saved embeddings for batch: 45\n",
      "Saved embeddings for batch: 46\n",
      "Saved embeddings for batch: 47\n",
      "Saved embeddings for batch: 48\n",
      "Saved embeddings for batch: 49\n",
      "Saved embeddings for batch: 50\n",
      "Saved embeddings for batch: 51\n",
      "Saved embeddings for batch: 52\n",
      "Saved embeddings for batch: 53\n",
      "Saved embeddings for batch: 54\n",
      "Saved embeddings for batch: 55\n",
      "Saved embeddings for batch: 56\n",
      "Saved embeddings for batch: 57\n",
      "Saved embeddings for batch: 58\n",
      "Saved embeddings for batch: 59\n",
      "Saved embeddings for batch: 60\n",
      "Saved embeddings for batch: 61\n",
      "Saved embeddings for batch: 62\n",
      "Saved embeddings for batch: 63\n",
      "Saved embeddings for batch: 64\n",
      "Saved embeddings for batch: 65\n",
      "Saved embeddings for batch: 66\n",
      "Saved embeddings for batch: 67\n",
      "Saved embeddings for batch: 68\n",
      "Saved embeddings for batch: 69\n",
      "Saved embeddings for batch: 70\n",
      "Saved embeddings for batch: 71\n",
      "Saved embeddings for batch: 72\n",
      "Saved embeddings for batch: 73\n",
      "Saved embeddings for batch: 74\n",
      "Saved embeddings for batch: 75\n",
      "Saved embeddings for batch: 76\n",
      "Saved embeddings for batch: 77\n",
      "Saved embeddings for batch: 78\n",
      "Saved embeddings for batch: 79\n",
      "Saved embeddings for batch: 80\n",
      "Saved embeddings for batch: 81\n",
      "Saved embeddings for batch: 82\n",
      "Saved embeddings for batch: 83\n",
      "Saved embeddings for batch: 84\n",
      "Saved embeddings for batch: 85\n",
      "Saved embeddings for batch: 86\n",
      "Saved embeddings for batch: 87\n"
     ]
    }
   ],
   "source": [
    "save_embeddings_hdf5(train_loader, \"train_embeddings.h5\")\n",
    "save_embeddings_hdf5(val_loader, \"val_embeddings.h5\")\n",
    "save_embeddings_hdf5(test_loader, \"test_embeddings.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39ae1d98-9812-4221-afa4-17432bf7a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "504d8865-b072-44d8-bec1-2d1af005019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_hdf5(filename, batch_size=32):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        num_samples = f[\"embeddings\"].shape[0]  # Total samples\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            X_batch = torch.tensor(f[\"embeddings\"][i : i + batch_size], dtype=torch.float32).to(DEVICE)\n",
    "            y_batch = torch.tensor(f[\"labels\"][i : i + batch_size], dtype=torch.long).to(DEVICE)\n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ebd750f-ea7f-4567-a9ba-681ba901667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(1024)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(256, num_classes)  # Final layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        if x.shape[0] > 1:  # Apply BatchNorm only if batch size > 1\n",
    "            x = self.batch_norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "    \n",
    "        x = self.fc2(x)\n",
    "        if x.shape[0] > 1:\n",
    "            x = self.batch_norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "    \n",
    "        x = self.fc3(x)\n",
    "        if x.shape[0] > 1:\n",
    "            x = self.batch_norm3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9af434c0-713f-4747-add1-0dab59e5a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = next(load_embeddings_hdf5(\"train_embeddings.h5\"))[0].shape[1]  # Get feature size\n",
    "num_classes = 3  # Adjust based on labels\n",
    "model = MLPClassifier(input_dim, num_classes).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "376a2515-00cd-49fb-8c3d-a5d6a333e8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (fc1): Linear(in_features=393216, out_features=1024, bias=True)\n",
       "  (batch_norm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (batch_norm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (batch_norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       "  (fc4): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53eb668e-d4e1-4963-b601-55afd0f07f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "# classes = np.unique(train_labels)\n",
    "# class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=train_labels)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(DEVICE)).to(DEVICE)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e834bcc3-7120-45dd-bfd3-bbae86e4d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "\n",
    "# model = model.to(\"cuda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a8a0a0e-c841-46df-9644-88bf0b8a4420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.                         | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 1/100 Train: 101it [00:11,  8.56it/s, acc=33.1, loss=1.25]                                                                                            \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 49.14it/s, acc=40.4, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\n",
      "  Train Loss: 0.0737 | Train Acc: 33.08%\n",
      "  Val Loss: 0.0697 | Val Acc: 40.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Train: 101it [00:11,  8.45it/s, acc=35.8, loss=0.83]                                                                                            \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.44it/s, acc=41.3, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100]\n",
      "  Train Loss: 0.0728 | Train Acc: 35.83%\n",
      "  Val Loss: 0.0690 | Val Acc: 41.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Train: 101it [00:11,  8.62it/s, acc=37.9, loss=1.11]                                                                                            \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.83it/s, acc=44.2, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100]\n",
      "  Train Loss: 0.0717 | Train Acc: 37.88%\n",
      "  Val Loss: 0.0685 | Val Acc: 44.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Train: 101it [00:11,  8.64it/s, acc=40.2, loss=1.24]                                                                                            \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.66it/s, acc=44.5, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100]\n",
      "  Train Loss: 0.0709 | Train Acc: 40.19%\n",
      "  Val Loss: 0.0681 | Val Acc: 44.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Train: 101it [00:11,  8.70it/s, acc=40.3, loss=0.966]                                                                                           \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.21it/s, acc=43.9, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100]\n",
      "  Train Loss: 0.0704 | Train Acc: 40.31%\n",
      "  Val Loss: 0.0683 | Val Acc: 43.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Train: 101it [00:11,  8.45it/s, acc=40.1, loss=1.18]                                                                                            \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.17it/s, acc=42.7, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100]\n",
      "  Train Loss: 0.0698 | Train Acc: 40.06%\n",
      "  Val Loss: 0.0679 | Val Acc: 42.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Train: 101it [00:11,  8.57it/s, acc=43.9, loss=0.911]                                                                                           \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.17it/s, acc=45.1, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100]\n",
      "  Train Loss: 0.0689 | Train Acc: 43.93%\n",
      "  Val Loss: 0.0677 | Val Acc: 45.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 Train: 101it [00:11,  8.60it/s, acc=41.3, loss=0.941]                                                                                           \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 51.86it/s, acc=47.4, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100]\n",
      "  Train Loss: 0.0690 | Train Acc: 41.31%\n",
      "  Val Loss: 0.0675 | Val Acc: 47.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 Train: 101it [00:11,  8.65it/s, acc=41.9, loss=0.803]                                                                                           \n",
      "Validation:  22%|███████████████████▏                                                                   | 22/100 [00:00<00:01, 50.75it/s, acc=52, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100]\n",
      "  Train Loss: 0.0689 | Train Acc: 41.87%\n",
      "  Val Loss: 0.0670 | Val Acc: 52.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 Train: 101it [00:11,  8.63it/s, acc=40.9, loss=0.982]                                                                                          \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.55it/s, acc=49.1, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100]\n",
      "  Train Loss: 0.0687 | Train Acc: 40.87%\n",
      "  Val Loss: 0.0672 | Val Acc: 49.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 Train: 101it [00:11,  8.44it/s, acc=44.8, loss=1.02]                                                                                           \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.89it/s, acc=53.2, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100]\n",
      "  Train Loss: 0.0670 | Train Acc: 44.80%\n",
      "  Val Loss: 0.0660 | Val Acc: 53.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 Train: 101it [00:11,  8.65it/s, acc=43.2, loss=1.15]                                                                                           \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 49.70it/s, acc=49.7, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100]\n",
      "  Train Loss: 0.0680 | Train Acc: 43.18%\n",
      "  Val Loss: 0.0664 | Val Acc: 49.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 Train: 101it [00:11,  8.64it/s, acc=45.9, loss=0.749]                                                                                          \n",
      "Validation:  22%|███████████████████▏                                                                   | 22/100 [00:00<00:01, 50.59it/s, acc=48, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100]\n",
      "  Train Loss: 0.0667 | Train Acc: 45.92%\n",
      "  Val Loss: 0.0664 | Val Acc: 47.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 Train: 101it [00:11,  8.63it/s, acc=47, loss=0.839]                                                                                            \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.72it/s, acc=51.5, loss=0.986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100]\n",
      "  Train Loss: 0.0652 | Train Acc: 47.04%\n",
      "  Val Loss: 0.0654 | Val Acc: 51.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 Train: 101it [00:11,  8.65it/s, acc=48.5, loss=0.965]                                                                                          \n",
      "Validation:  22%|███████████████████▎                                                                    | 22/100 [00:00<00:01, 50.41it/s, acc=49.1, loss=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100]\n",
      "  Train Loss: 0.0648 | Train Acc: 48.47%\n",
      "  Val Loss: 0.0653 | Val Acc: 49.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 Train: 101it [00:11,  8.65it/s, acc=47.9, loss=0.776]                                                                                          \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.38it/s, acc=52.6, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100]\n",
      "  Train Loss: 0.0654 | Train Acc: 47.91%\n",
      "  Val Loss: 0.0648 | Val Acc: 52.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 Train: 101it [00:11,  8.62it/s, acc=50, loss=0.821]                                                                                            \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 51.27it/s, acc=53.8, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100]\n",
      "  Train Loss: 0.0640 | Train Acc: 50.03%\n",
      "  Val Loss: 0.0648 | Val Acc: 53.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 Train: 101it [00:11,  8.44it/s, acc=50.2, loss=0.85]                                                                                           \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 51.05it/s, acc=53.5, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100]\n",
      "  Train Loss: 0.0625 | Train Acc: 50.22%\n",
      "  Val Loss: 0.0645 | Val Acc: 53.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 Train: 101it [00:11,  8.64it/s, acc=51.3, loss=1.01]                                                                                           \n",
      "Validation:  22%|███████████████████▏                                                                   | 22/100 [00:00<00:01, 50.95it/s, acc=50, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100]\n",
      "  Train Loss: 0.0622 | Train Acc: 51.34%\n",
      "  Val Loss: 0.0642 | Val Acc: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 Train: 101it [00:11,  8.65it/s, acc=54.5, loss=0.758]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.64it/s, acc=52.6, loss=0.898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100]\n",
      "  Train Loss: 0.0604 | Train Acc: 54.45%\n",
      "  Val Loss: 0.0640 | Val Acc: 52.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 Train: 101it [00:11,  8.47it/s, acc=55.4, loss=0.858]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.32it/s, acc=51.7, loss=0.955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100]\n",
      "  Train Loss: 0.0598 | Train Acc: 55.39%\n",
      "  Val Loss: 0.0640 | Val Acc: 51.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 Train: 101it [00:11,  8.63it/s, acc=55.1, loss=0.768]                                                                                          \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.89it/s, acc=56.4, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100]\n",
      "  Train Loss: 0.0596 | Train Acc: 55.08%\n",
      "  Val Loss: 0.0634 | Val Acc: 56.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 Train: 101it [00:11,  8.63it/s, acc=57.4, loss=0.899]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.42it/s, acc=51.7, loss=0.915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100]\n",
      "  Train Loss: 0.0582 | Train Acc: 57.38%\n",
      "  Val Loss: 0.0631 | Val Acc: 51.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 Train: 101it [00:11,  8.65it/s, acc=54.4, loss=0.971]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.95it/s, acc=55.2, loss=0.915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100]\n",
      "  Train Loss: 0.0587 | Train Acc: 54.39%\n",
      "  Val Loss: 0.0628 | Val Acc: 55.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 Train: 101it [00:11,  8.47it/s, acc=57.4, loss=0.889]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 49.52it/s, acc=57.6, loss=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100]\n",
      "  Train Loss: 0.0575 | Train Acc: 57.45%\n",
      "  Val Loss: 0.0620 | Val Acc: 57.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 Train: 101it [00:11,  8.62it/s, acc=58.1, loss=0.665]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.04it/s, acc=55.8, loss=0.962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100]\n",
      "  Train Loss: 0.0554 | Train Acc: 58.13%\n",
      "  Val Loss: 0.0622 | Val Acc: 55.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 Train: 101it [00:11,  8.64it/s, acc=62.2, loss=0.601]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.86it/s, acc=55.5, loss=0.899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100]\n",
      "  Train Loss: 0.0530 | Train Acc: 62.18%\n",
      "  Val Loss: 0.0612 | Val Acc: 55.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 Train: 101it [00:11,  8.64it/s, acc=60.1, loss=0.522]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 49.70it/s, acc=54.9, loss=0.938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100]\n",
      "  Train Loss: 0.0529 | Train Acc: 60.06%\n",
      "  Val Loss: 0.0610 | Val Acc: 54.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 Train: 101it [00:11,  8.61it/s, acc=63.6, loss=0.599]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.06it/s, acc=55.8, loss=0.886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100]\n",
      "  Train Loss: 0.0513 | Train Acc: 63.55%\n",
      "  Val Loss: 0.0597 | Val Acc: 55.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 Train: 101it [00:11,  8.65it/s, acc=64.4, loss=0.794]                                                                                          \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.74it/s, acc=57.8, loss=0.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100]\n",
      "  Train Loss: 0.0503 | Train Acc: 64.42%\n",
      "  Val Loss: 0.0599 | Val Acc: 57.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 Train: 101it [00:11,  8.63it/s, acc=65.4, loss=0.521]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.34it/s, acc=58.7, loss=0.895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100]\n",
      "  Train Loss: 0.0495 | Train Acc: 65.42%\n",
      "  Val Loss: 0.0585 | Val Acc: 58.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 Train: 101it [00:11,  8.63it/s, acc=67.4, loss=0.654]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.91it/s, acc=60.8, loss=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100]\n",
      "  Train Loss: 0.0482 | Train Acc: 67.41%\n",
      "  Val Loss: 0.0586 | Val Acc: 60.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 Train: 101it [00:12,  8.42it/s, acc=66, loss=0.541]                                                                                            \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 49.90it/s, acc=57.3, loss=0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100]\n",
      "  Train Loss: 0.0475 | Train Acc: 66.04%\n",
      "  Val Loss: 0.0593 | Val Acc: 57.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 Train: 101it [00:11,  8.63it/s, acc=69, loss=0.407]                                                                                            \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.67it/s, acc=61.9, loss=0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100]\n",
      "  Train Loss: 0.0450 | Train Acc: 69.03%\n",
      "  Val Loss: 0.0572 | Val Acc: 61.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 Train: 101it [00:11,  8.64it/s, acc=70.8, loss=0.763]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 52.43it/s, acc=61, loss=0.728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100]\n",
      "  Train Loss: 0.0450 | Train Acc: 70.84%\n",
      "  Val Loss: 0.0571 | Val Acc: 61.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 Train: 101it [00:11,  8.63it/s, acc=71.8, loss=0.551]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.70it/s, acc=61, loss=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100]\n",
      "  Train Loss: 0.0432 | Train Acc: 71.78%\n",
      "  Val Loss: 0.0568 | Val Acc: 61.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 Train: 101it [00:11,  8.62it/s, acc=74.5, loss=0.803]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.31it/s, acc=61, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100]\n",
      "  Train Loss: 0.0409 | Train Acc: 74.52%\n",
      "  Val Loss: 0.0578 | Val Acc: 61.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 Train: 101it [00:11,  8.64it/s, acc=74.5, loss=0.557]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.63it/s, acc=60.2, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100]\n",
      "  Train Loss: 0.0404 | Train Acc: 74.52%\n",
      "  Val Loss: 0.0570 | Val Acc: 60.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 Train: 101it [00:11,  8.63it/s, acc=75.9, loss=0.384]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.38it/s, acc=59.9, loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100]\n",
      "  Train Loss: 0.0380 | Train Acc: 75.89%\n",
      "  Val Loss: 0.0578 | Val Acc: 59.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 Train: 101it [00:11,  8.47it/s, acc=77, loss=0.431]                                                                                            \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.12it/s, acc=57.6, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100]\n",
      "  Train Loss: 0.0379 | Train Acc: 77.01%\n",
      "  Val Loss: 0.0577 | Val Acc: 57.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 Train: 101it [00:11,  8.63it/s, acc=78.3, loss=0.482]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.67it/s, acc=59.9, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100]\n",
      "  Train Loss: 0.0356 | Train Acc: 78.26%\n",
      "  Val Loss: 0.0573 | Val Acc: 59.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 Train: 101it [00:11,  8.65it/s, acc=77.8, loss=0.393]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.05it/s, acc=60.2, loss=0.712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100]\n",
      "  Train Loss: 0.0353 | Train Acc: 77.76%\n",
      "  Val Loss: 0.0566 | Val Acc: 60.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 Train: 101it [00:11,  8.64it/s, acc=79.8, loss=0.471]                                                                                          \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 50.48it/s, acc=58.1, loss=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100]\n",
      "  Train Loss: 0.0335 | Train Acc: 79.81%\n",
      "  Val Loss: 0.0563 | Val Acc: 58.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 Train: 101it [00:11,  8.44it/s, acc=81.2, loss=0.333]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.59it/s, acc=59.6, loss=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100]\n",
      "  Train Loss: 0.0321 | Train Acc: 81.18%\n",
      "  Val Loss: 0.0571 | Val Acc: 59.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 Train: 101it [00:11,  8.63it/s, acc=80.5, loss=0.414]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.65it/s, acc=59.6, loss=0.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100]\n",
      "  Train Loss: 0.0313 | Train Acc: 80.50%\n",
      "  Val Loss: 0.0549 | Val Acc: 59.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 Train: 101it [00:11,  8.71it/s, acc=83.6, loss=0.362]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 49.43it/s, acc=60.2, loss=0.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100]\n",
      "  Train Loss: 0.0300 | Train Acc: 83.55%\n",
      "  Val Loss: 0.0580 | Val Acc: 60.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 Train: 101it [00:11,  8.61it/s, acc=83.9, loss=0.298]                                                                                          \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 51.33it/s, acc=61.9, loss=0.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100]\n",
      "  Train Loss: 0.0287 | Train Acc: 83.93%\n",
      "  Val Loss: 0.0563 | Val Acc: 61.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 Train: 101it [00:11,  8.46it/s, acc=84.7, loss=0.411]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.66it/s, acc=58.4, loss=0.662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100]\n",
      "  Train Loss: 0.0277 | Train Acc: 84.67%\n",
      "  Val Loss: 0.0548 | Val Acc: 58.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 Train: 101it [00:11,  8.64it/s, acc=85.9, loss=0.237]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 49.73it/s, acc=57.6, loss=0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100]\n",
      "  Train Loss: 0.0265 | Train Acc: 85.92%\n",
      "  Val Loss: 0.0569 | Val Acc: 57.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 Train: 101it [00:11,  8.63it/s, acc=87.8, loss=0.258]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.99it/s, acc=61.6, loss=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100]\n",
      "  Train Loss: 0.0253 | Train Acc: 87.79%\n",
      "  Val Loss: 0.0569 | Val Acc: 61.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 Train: 101it [00:11,  8.63it/s, acc=85.3, loss=0.268]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.25it/s, acc=58.1, loss=0.537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100]\n",
      "  Train Loss: 0.0256 | Train Acc: 85.30%\n",
      "  Val Loss: 0.0571 | Val Acc: 58.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 Train: 101it [00:11,  8.46it/s, acc=86.7, loss=0.302]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.53it/s, acc=61, loss=0.608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100]\n",
      "  Train Loss: 0.0245 | Train Acc: 86.67%\n",
      "  Val Loss: 0.0544 | Val Acc: 61.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 Train: 101it [00:11,  8.63it/s, acc=88.2, loss=0.484]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 51.87it/s, acc=64, loss=0.551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100]\n",
      "  Train Loss: 0.0238 | Train Acc: 88.22%\n",
      "  Val Loss: 0.0590 | Val Acc: 63.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 Train: 101it [00:11,  8.64it/s, acc=90.9, loss=0.209]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.21it/s, acc=66, loss=0.599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100]\n",
      "  Train Loss: 0.0214 | Train Acc: 90.90%\n",
      "  Val Loss: 0.0584 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 Train: 101it [00:11,  8.66it/s, acc=90.3, loss=0.298]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.15it/s, acc=61.9, loss=0.557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100]\n",
      "  Train Loss: 0.0206 | Train Acc: 90.28%\n",
      "  Val Loss: 0.0571 | Val Acc: 61.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 Train: 101it [00:11,  8.44it/s, acc=90.6, loss=0.251]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.23it/s, acc=63.4, loss=0.548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100]\n",
      "  Train Loss: 0.0197 | Train Acc: 90.59%\n",
      "  Val Loss: 0.0566 | Val Acc: 63.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 Train: 101it [00:11,  8.58it/s, acc=92, loss=0.263]                                                                                            \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.62it/s, acc=63.1, loss=0.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100]\n",
      "  Train Loss: 0.0187 | Train Acc: 92.02%\n",
      "  Val Loss: 0.0576 | Val Acc: 63.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 Train: 101it [00:11,  8.62it/s, acc=92, loss=0.307]                                                                                            \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.07it/s, acc=62.5, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100]\n",
      "  Train Loss: 0.0184 | Train Acc: 91.96%\n",
      "  Val Loss: 0.0577 | Val Acc: 62.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 Train: 101it [00:11,  8.61it/s, acc=93.1, loss=0.127]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.49it/s, acc=64.2, loss=0.633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100]\n",
      "  Train Loss: 0.0167 | Train Acc: 93.08%\n",
      "  Val Loss: 0.0539 | Val Acc: 64.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 Train: 101it [00:11,  8.62it/s, acc=94.8, loss=0.253]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.39it/s, acc=64.5, loss=0.538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100]\n",
      "  Train Loss: 0.0148 | Train Acc: 94.83%\n",
      "  Val Loss: 0.0547 | Val Acc: 64.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 Train: 101it [00:11,  8.62it/s, acc=94.9, loss=0.235]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.40it/s, acc=67.7, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100]\n",
      "  Train Loss: 0.0136 | Train Acc: 94.89%\n",
      "  Val Loss: 0.0536 | Val Acc: 67.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 Train: 101it [00:11,  8.61it/s, acc=96.3, loss=0.169]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.63it/s, acc=65.7, loss=0.566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100]\n",
      "  Train Loss: 0.0132 | Train Acc: 96.26%\n",
      "  Val Loss: 0.0539 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 Train: 101it [00:11,  8.64it/s, acc=96.6, loss=0.115]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.03it/s, acc=64.5, loss=0.496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100]\n",
      "  Train Loss: 0.0121 | Train Acc: 96.64%\n",
      "  Val Loss: 0.0545 | Val Acc: 64.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 Train: 101it [00:11,  8.61it/s, acc=96, loss=0.14]                                                                                             \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 49.77it/s, acc=65.1, loss=0.516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100]\n",
      "  Train Loss: 0.0119 | Train Acc: 96.01%\n",
      "  Val Loss: 0.0544 | Val Acc: 65.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 Train: 101it [00:11,  8.62it/s, acc=96.6, loss=0.138]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.43it/s, acc=64.2, loss=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100]\n",
      "  Train Loss: 0.0116 | Train Acc: 96.57%\n",
      "  Val Loss: 0.0552 | Val Acc: 64.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 Train: 101it [00:11,  8.69it/s, acc=96.6, loss=0.228]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.19it/s, acc=63.7, loss=0.617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100]\n",
      "  Train Loss: 0.0118 | Train Acc: 96.57%\n",
      "  Val Loss: 0.0542 | Val Acc: 63.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 Train: 101it [00:11,  8.63it/s, acc=96.9, loss=0.273]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 49.45it/s, acc=65.4, loss=0.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100]\n",
      "  Train Loss: 0.0106 | Train Acc: 96.88%\n",
      "  Val Loss: 0.0548 | Val Acc: 65.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 Train: 101it [00:11,  8.61it/s, acc=97.9, loss=0.248]                                                                                          \n",
      "Validation:  22%|███████████████████▏                                                                   | 22/100 [00:00<00:01, 51.44it/s, acc=66, loss=0.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100]\n",
      "  Train Loss: 0.0097 | Train Acc: 97.94%\n",
      "  Val Loss: 0.0542 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 Train: 101it [00:11,  8.63it/s, acc=97.9, loss=0.114]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.85it/s, acc=65.4, loss=0.531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100]\n",
      "  Train Loss: 0.0096 | Train Acc: 97.94%\n",
      "  Val Loss: 0.0534 | Val Acc: 65.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 Train: 101it [00:11,  8.65it/s, acc=98.1, loss=0.178]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.61it/s, acc=64.8, loss=0.582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100]\n",
      "  Train Loss: 0.0090 | Train Acc: 98.13%\n",
      "  Val Loss: 0.0532 | Val Acc: 64.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 Train: 101it [00:11,  8.63it/s, acc=97.9, loss=0.142]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.99it/s, acc=64.8, loss=0.555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100]\n",
      "  Train Loss: 0.0088 | Train Acc: 97.94%\n",
      "  Val Loss: 0.0542 | Val Acc: 64.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 Train: 101it [00:11,  8.64it/s, acc=97.7, loss=0.157]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 51.45it/s, acc=66, loss=0.483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100]\n",
      "  Train Loss: 0.0091 | Train Acc: 97.69%\n",
      "  Val Loss: 0.0542 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 Train: 101it [00:11,  8.63it/s, acc=98.6, loss=0.151]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.81it/s, acc=65.7, loss=0.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100]\n",
      "  Train Loss: 0.0083 | Train Acc: 98.57%\n",
      "  Val Loss: 0.0544 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 Train: 101it [00:11,  8.63it/s, acc=98.2, loss=0.169]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 52.61it/s, acc=66, loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100]\n",
      "  Train Loss: 0.0085 | Train Acc: 98.19%\n",
      "  Val Loss: 0.0556 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 Train: 101it [00:11,  8.65it/s, acc=98.9, loss=0.104]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.48it/s, acc=65.4, loss=0.516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100]\n",
      "  Train Loss: 0.0078 | Train Acc: 98.88%\n",
      "  Val Loss: 0.0531 | Val Acc: 65.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 Train: 101it [00:11,  8.61it/s, acc=98.9, loss=0.181]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.34it/s, acc=64.5, loss=0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100]\n",
      "  Train Loss: 0.0079 | Train Acc: 98.88%\n",
      "  Val Loss: 0.0536 | Val Acc: 64.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 Train: 101it [00:11,  8.61it/s, acc=99.1, loss=0.206]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.17it/s, acc=64.8, loss=0.496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100]\n",
      "  Train Loss: 0.0078 | Train Acc: 99.07%\n",
      "  Val Loss: 0.0542 | Val Acc: 64.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 Train: 101it [00:11,  8.62it/s, acc=98.9, loss=0.0673]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.31it/s, acc=67.2, loss=0.439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100]\n",
      "  Train Loss: 0.0075 | Train Acc: 98.94%\n",
      "  Val Loss: 0.0544 | Val Acc: 67.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 Train: 101it [00:11,  8.63it/s, acc=99.2, loss=0.145]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.19it/s, acc=65.1, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100]\n",
      "  Train Loss: 0.0072 | Train Acc: 99.19%\n",
      "  Val Loss: 0.0541 | Val Acc: 65.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 Train: 101it [00:11,  8.63it/s, acc=99.2, loss=0.16]                                                                                           \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 52.52it/s, acc=64.5, loss=0.475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100]\n",
      "  Train Loss: 0.0073 | Train Acc: 99.19%\n",
      "  Val Loss: 0.0548 | Val Acc: 64.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 Train: 101it [00:11,  8.62it/s, acc=99.1, loss=0.175]                                                                                          \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.88it/s, acc=65.1, loss=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100]\n",
      "  Train Loss: 0.0071 | Train Acc: 99.07%\n",
      "  Val Loss: 0.0545 | Val Acc: 65.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 Train: 101it [00:11,  8.63it/s, acc=99.1, loss=0.348]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 50.86it/s, acc=66.3, loss=0.481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100]\n",
      "  Train Loss: 0.0070 | Train Acc: 99.13%\n",
      "  Val Loss: 0.0549 | Val Acc: 66.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 Train: 101it [00:11,  8.60it/s, acc=99.4, loss=0.223]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.70it/s, acc=65.7, loss=0.507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100]\n",
      "  Train Loss: 0.0066 | Train Acc: 99.38%\n",
      "  Val Loss: 0.0539 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 Train: 101it [00:11,  8.64it/s, acc=99.3, loss=0.195]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.70it/s, acc=65.4, loss=0.503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100]\n",
      "  Train Loss: 0.0069 | Train Acc: 99.25%\n",
      "  Val Loss: 0.0540 | Val Acc: 65.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 Train: 101it [00:11,  8.66it/s, acc=99.4, loss=0.0901]                                                                                         \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 50.51it/s, acc=66, loss=0.526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100]\n",
      "  Train Loss: 0.0065 | Train Acc: 99.38%\n",
      "  Val Loss: 0.0542 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 Train: 101it [00:11,  8.62it/s, acc=99.3, loss=0.0878]                                                                                         \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 51.34it/s, acc=65.7, loss=0.541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100]\n",
      "  Train Loss: 0.0064 | Train Acc: 99.31%\n",
      "  Val Loss: 0.0533 | Val Acc: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 Train: 101it [00:11,  8.63it/s, acc=99.6, loss=0.0767]                                                                                         \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 51.51it/s, acc=66, loss=0.479]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100]\n",
      "  Train Loss: 0.0062 | Train Acc: 99.63%\n",
      "  Val Loss: 0.0537 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 Train: 101it [00:11,  8.64it/s, acc=99.4, loss=0.172]                                                                                          \n",
      "Validation:  22%|██████████████████▍                                                                 | 22/100 [00:00<00:01, 49.70it/s, acc=66.6, loss=0.489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100]\n",
      "  Train Loss: 0.0064 | Train Acc: 99.38%\n",
      "  Val Loss: 0.0543 | Val Acc: 66.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 Train: 101it [00:11,  8.62it/s, acc=99.3, loss=0.14]                                                                                           \n",
      "Validation:  22%|██████████████████▉                                                                   | 22/100 [00:00<00:01, 52.31it/s, acc=66, loss=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100]\n",
      "  Train Loss: 0.0059 | Train Acc: 99.31%\n",
      "  Val Loss: 0.0544 | Val Acc: 65.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 Train: 101it [00:11,  8.65it/s, acc=99.6, loss=0.082]                                                                                          \n",
      "Validation:  22%|██████████████████▋                                                                  | 22/100 [00:00<00:01, 51.53it/s, acc=66.3, loss=0.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 90. No improvement in validation loss for 15 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # Progress tracking\n",
    "\n",
    "# Compute class weights\n",
    "def compute_class_weights(y_train):\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    return torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "y_train = np.concatenate([y.cpu().numpy() for _, y in load_embeddings_hdf5(\"train_embeddings.h5\", batch_size=32)])\n",
    "class_weights = compute_class_weights(y_train)\n",
    "\n",
    "# Define optimizer, scheduler, and scaler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "NUM_GPUS = 1\n",
    "num_epochs = 100\n",
    "patience = 15  # Early stopping patience\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    # Training loop\n",
    "    train_loader = load_embeddings_hdf5(\"train_embeddings.h5\", batch_size=16 * NUM_GPUS)  # Adjust batch size\n",
    "    train_bar = tqdm(train_loader, total=len(y_train) // (16 * NUM_GPUS), desc=f\"Epoch {epoch+1}/{num_epochs} Train\")\n",
    "    for X_batch, y_batch in train_bar:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():  # Mixed precision\n",
    "            outputs = model(X_batch)\n",
    "            loss = F.cross_entropy(outputs, y_batch, weight=class_weights)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "        \n",
    "        train_bar.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    avg_train_loss = train_loss / total\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    val_loader = load_embeddings_hdf5(\"val_embeddings.h5\", batch_size=16 * NUM_GPUS)\n",
    "    val_bar = tqdm(val_loader, total=len(y_train) // (16 * NUM_GPUS), desc=\"Validation\")\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_bar:\n",
    "            X_val, y_val = X_val.to(DEVICE), y_val.to(DEVICE)\n",
    "            outputs = model(X_val)\n",
    "            loss = F.cross_entropy(outputs, y_val, weight=class_weights)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(y_val).sum().item()\n",
    "            val_total += y_val.size(0)\n",
    "\n",
    "            val_bar.set_postfix(loss=loss.item(), acc=100 * val_correct / val_total)\n",
    "    \n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    avg_val_loss = val_loss / val_total\n",
    "\n",
    "    # Check for early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Stop if no improvement for 10 epochs\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}. No improvement in validation loss for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "    # Learning rate scheduler step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}%\")\n",
    "    print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d024b1eb-13bb-41ee-8713-81f9db73ccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6029\n",
      "Precision: 0.5990\n",
      "Recall: 0.6029\n",
      "F1 Score: 0.5983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Inference\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in load_embeddings_hdf5(\"test_embeddings.h5\", batch_size=4):\n",
    "        outputs = model(X_batch)\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(y_batch.cpu().numpy())\n",
    "        y_pred.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average=\"weighted\")  # \"weighted\" accounts for class imbalance\n",
    "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3624e339-8d75-4321-a077-16afba000ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55       106\n",
      "           1       0.65      0.73      0.69       167\n",
      "           2       0.48      0.46      0.47        72\n",
      "\n",
      "    accuracy                           0.60       345\n",
      "   macro avg       0.58      0.56      0.57       345\n",
      "weighted avg       0.60      0.60      0.60       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
